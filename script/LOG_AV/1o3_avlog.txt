maxpool
latent size single: 16
loading dataset
16
creating model
start training
[8/15000], training loss: 0.1378
[16/15000], training loss: 0.1326
[24/15000], training loss: 0.1258
[32/15000], training loss: 0.1236
[40/15000], training loss: 0.1185
16
AVD_Office_001_1_traj3, ate: 480.23236573393774
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[48/15000], training loss: 0.1210
[56/15000], training loss: 0.1201
[64/15000], training loss: 0.1165
[72/15000], training loss: 0.1205
[80/15000], training loss: 0.1233
16
AVD_Office_001_1_traj3, ate: 423.6926180291167
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[88/15000], training loss: 0.1210
[96/15000], training loss: 0.1115
[104/15000], training loss: 0.1102
[112/15000], training loss: 0.1183
[120/15000], training loss: 0.1171
16
AVD_Office_001_1_traj3, ate: 405.3658262289798
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[128/15000], training loss: 0.1139
[136/15000], training loss: 0.1066
[144/15000], training loss: 0.1138
[152/15000], training loss: 0.1198
[160/15000], training loss: 0.1042
16
AVD_Office_001_1_traj3, ate: 377.45962664023557
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[168/15000], training loss: 0.1091
[176/15000], training loss: 0.1015
[184/15000], training loss: 0.1097
[192/15000], training loss: 0.1206
[200/15000], training loss: 0.1134
16
AVD_Office_001_1_traj3, ate: 351.33466280248877
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[208/15000], training loss: 0.1109
[216/15000], training loss: 0.1019
[224/15000], training loss: 0.1104
[232/15000], training loss: 0.1072
[240/15000], training loss: 0.1028
16
AVD_Office_001_1_traj3, ate: 369.0910027659085
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[248/15000], training loss: 0.1015
[256/15000], training loss: 0.1026
[264/15000], training loss: 0.1118
[272/15000], training loss: 0.1112
[280/15000], training loss: 0.0947
16
AVD_Office_001_1_traj3, ate: 392.8518978736414
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[288/15000], training loss: 0.1037
[296/15000], training loss: 0.0976
[304/15000], training loss: 0.1066
[312/15000], training loss: 0.1104
[320/15000], training loss: 0.1009
16
AVD_Office_001_1_traj3, ate: 356.63539656221315
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[328/15000], training loss: 0.1173
[336/15000], training loss: 0.0990
[344/15000], training loss: 0.0951
[352/15000], training loss: 0.0981
[360/15000], training loss: 0.1012
16
AVD_Office_001_1_traj3, ate: 397.4071050928452
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[368/15000], training loss: 0.1107
[376/15000], training loss: 0.0936
[384/15000], training loss: 0.0968
[392/15000], training loss: 0.1033
[400/15000], training loss: 0.0961
16
AVD_Office_001_1_traj3, ate: 402.4174322093373
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[408/15000], training loss: 0.0990
[416/15000], training loss: 0.1103
[424/15000], training loss: 0.1124
[432/15000], training loss: 0.1018
[440/15000], training loss: 0.0917
16
AVD_Office_001_1_traj3, ate: 409.2515766957839
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[448/15000], training loss: 0.1026
[456/15000], training loss: 0.0991
[464/15000], training loss: 0.0845
[472/15000], training loss: 0.1010
[480/15000], training loss: 0.0982
16
AVD_Office_001_1_traj3, ate: 386.39793939589924
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[488/15000], training loss: 0.0931
[496/15000], training loss: 0.0940
[504/15000], training loss: 0.0856
[512/15000], training loss: 0.0968
[520/15000], training loss: 0.1044
16
AVD_Office_001_1_traj3, ate: 380.681390734484
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[528/15000], training loss: 0.1093
[536/15000], training loss: 0.0900
[544/15000], training loss: 0.0962
[552/15000], training loss: 0.0946
[560/15000], training loss: 0.0909
16
AVD_Office_001_1_traj3, ate: 378.2395338675968
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[568/15000], training loss: 0.1038
[576/15000], training loss: 0.0998
[584/15000], training loss: 0.0961
[592/15000], training loss: 0.1099
[600/15000], training loss: 0.1058
16
AVD_Office_001_1_traj3, ate: 352.8360887206454
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[608/15000], training loss: 0.0932
[616/15000], training loss: 0.0805
[624/15000], training loss: 0.0987
[632/15000], training loss: 0.0822
[640/15000], training loss: 0.0874
16
AVD_Office_001_1_traj3, ate: 360.82199739590044
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[648/15000], training loss: 0.0799
[656/15000], training loss: 0.0873
[664/15000], training loss: 0.1039
[672/15000], training loss: 0.1034
[680/15000], training loss: 0.0968
16
AVD_Office_001_1_traj3, ate: 375.09791524468864
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[688/15000], training loss: 0.1014
[696/15000], training loss: 0.0892
[704/15000], training loss: 0.0874
[712/15000], training loss: 0.0885
[720/15000], training loss: 0.0840
16
AVD_Office_001_1_traj3, ate: 355.61859550359844
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[728/15000], training loss: 0.0942
[736/15000], training loss: 0.0912
[744/15000], training loss: 0.0988
[752/15000], training loss: 0.0962
[760/15000], training loss: 0.0834
16
AVD_Office_001_1_traj3, ate: 324.9507772234182
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[768/15000], training loss: 0.0919
[776/15000], training loss: 0.0986
[784/15000], training loss: 0.1005
[792/15000], training loss: 0.0952
[800/15000], training loss: 0.0923
16
AVD_Office_001_1_traj3, ate: 318.626352251344
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[808/15000], training loss: 0.0829
[816/15000], training loss: 0.0928
[824/15000], training loss: 0.0918
[832/15000], training loss: 0.0805
[840/15000], training loss: 0.0801
16
AVD_Office_001_1_traj3, ate: 312.8991460900024
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[848/15000], training loss: 0.0923
[856/15000], training loss: 0.0908
[864/15000], training loss: 0.1088
[872/15000], training loss: 0.0979
[880/15000], training loss: 0.0959
16
AVD_Office_001_1_traj3, ate: 318.58250397052257
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[888/15000], training loss: 0.0963
[896/15000], training loss: 0.0857
[904/15000], training loss: 0.0775
[912/15000], training loss: 0.0813
[920/15000], training loss: 0.0823
16
AVD_Office_001_1_traj3, ate: 302.9986052295621
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[928/15000], training loss: 0.0796
[936/15000], training loss: 0.0877
[944/15000], training loss: 0.0851
[952/15000], training loss: 0.0815
[960/15000], training loss: 0.0745
16
AVD_Office_001_1_traj3, ate: 280.7236818578666
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[968/15000], training loss: 0.0832
[976/15000], training loss: 0.0791
[984/15000], training loss: 0.0978
[992/15000], training loss: 0.0964
[1000/15000], training loss: 0.0883
16
AVD_Office_001_1_traj3, ate: 252.17439901002498
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1008/15000], training loss: 0.0940
[1016/15000], training loss: 0.0777
[1024/15000], training loss: 0.0772
[1032/15000], training loss: 0.0814
[1040/15000], training loss: 0.0851
16
AVD_Office_001_1_traj3, ate: 252.7799191865898
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1048/15000], training loss: 0.0855
[1056/15000], training loss: 0.0863
[1064/15000], training loss: 0.0883
[1072/15000], training loss: 0.0806
[1080/15000], training loss: 0.0944
16
AVD_Office_001_1_traj3, ate: 242.4664728069067
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1088/15000], training loss: 0.0940
[1096/15000], training loss: 0.0881
[1104/15000], training loss: 0.0854
[1112/15000], training loss: 0.0729
[1120/15000], training loss: 0.0766
16
AVD_Office_001_1_traj3, ate: 232.02370525146512
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1128/15000], training loss: 0.1069
[1136/15000], training loss: 0.0826
[1144/15000], training loss: 0.0953
[1152/15000], training loss: 0.0964
[1160/15000], training loss: 0.0972
16
AVD_Office_001_1_traj3, ate: 227.7789429604874
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1168/15000], training loss: 0.0774
[1176/15000], training loss: 0.0882
[1184/15000], training loss: 0.0885
[1192/15000], training loss: 0.0835
[1200/15000], training loss: 0.0772
16
AVD_Office_001_1_traj3, ate: 214.83951192578957
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1208/15000], training loss: 0.0812
[1216/15000], training loss: 0.0777
[1224/15000], training loss: 0.0818
[1232/15000], training loss: 0.0892
[1240/15000], training loss: 0.0817
16
AVD_Office_001_1_traj3, ate: 199.91944076830228
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1248/15000], training loss: 0.1011
[1256/15000], training loss: 0.0807
[1264/15000], training loss: 0.0714
[1272/15000], training loss: 0.0854
[1280/15000], training loss: 0.0777
16
AVD_Office_001_1_traj3, ate: 221.79960244613682
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1288/15000], training loss: 0.0763
[1296/15000], training loss: 0.1035
[1304/15000], training loss: 0.0818
[1312/15000], training loss: 0.0880
[1320/15000], training loss: 0.0891
16
AVD_Office_001_1_traj3, ate: 174.43070970726615
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1328/15000], training loss: 0.0684
[1336/15000], training loss: 0.0866
[1344/15000], training loss: 0.0744
[1352/15000], training loss: 0.1003
[1360/15000], training loss: 0.0747
16
AVD_Office_001_1_traj3, ate: 191.22188156821798
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1368/15000], training loss: 0.0908
[1376/15000], training loss: 0.0840
[1384/15000], training loss: 0.0762
[1392/15000], training loss: 0.0770
[1400/15000], training loss: 0.0981
16
AVD_Office_001_1_traj3, ate: 179.44596178597683
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1408/15000], training loss: 0.0744
[1416/15000], training loss: 0.0682
[1424/15000], training loss: 0.0997
[1432/15000], training loss: 0.0920
[1440/15000], training loss: 0.0895
16
AVD_Office_001_1_traj3, ate: 198.0894097505898
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1448/15000], training loss: 0.0852
[1456/15000], training loss: 0.0766
[1464/15000], training loss: 0.0736
[1472/15000], training loss: 0.0909
[1480/15000], training loss: 0.0774
16
AVD_Office_001_1_traj3, ate: 155.6860709412347
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1488/15000], training loss: 0.0799
[1496/15000], training loss: 0.0676
[1504/15000], training loss: 0.0801
[1512/15000], training loss: 0.0660
[1520/15000], training loss: 0.0795
16
AVD_Office_001_1_traj3, ate: 177.65155978545314
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1528/15000], training loss: 0.0785
[1536/15000], training loss: 0.0840
[1544/15000], training loss: 0.0817
[1552/15000], training loss: 0.0752
[1560/15000], training loss: 0.0731
16
AVD_Office_001_1_traj3, ate: 178.83031813255198
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1568/15000], training loss: 0.0827
[1576/15000], training loss: 0.1064
[1584/15000], training loss: 0.0753
[1592/15000], training loss: 0.0721
[1600/15000], training loss: 0.0851
16
AVD_Office_001_1_traj3, ate: 148.28632390524172
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1608/15000], training loss: 0.0792
[1616/15000], training loss: 0.0665
[1624/15000], training loss: 0.0694
[1632/15000], training loss: 0.0885
[1640/15000], training loss: 0.0736
16
AVD_Office_001_1_traj3, ate: 177.5334188617905
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1648/15000], training loss: 0.0812
[1656/15000], training loss: 0.1035
[1664/15000], training loss: 0.0925
[1672/15000], training loss: 0.0877
[1680/15000], training loss: 0.0732
16
AVD_Office_001_1_traj3, ate: 164.6016343239102
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1688/15000], training loss: 0.0798
[1696/15000], training loss: 0.0696
[1704/15000], training loss: 0.0796
[1712/15000], training loss: 0.0874
[1720/15000], training loss: 0.0905
16
AVD_Office_001_1_traj3, ate: 178.01537535294545
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1728/15000], training loss: 0.0767
[1736/15000], training loss: 0.0639
[1744/15000], training loss: 0.0723
[1752/15000], training loss: 0.0910
[1760/15000], training loss: 0.0724
16
AVD_Office_001_1_traj3, ate: 154.48387187666117
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1768/15000], training loss: 0.0865
[1776/15000], training loss: 0.0776
[1784/15000], training loss: 0.0686
[1792/15000], training loss: 0.0836
[1800/15000], training loss: 0.0929
16
AVD_Office_001_1_traj3, ate: 177.48264264021432
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1808/15000], training loss: 0.0905
[1816/15000], training loss: 0.0874
[1824/15000], training loss: 0.0918
[1832/15000], training loss: 0.0851
[1840/15000], training loss: 0.0926
16
AVD_Office_001_1_traj3, ate: 152.78030875721714
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1848/15000], training loss: 0.0855
[1856/15000], training loss: 0.0774
[1864/15000], training loss: 0.0626
[1872/15000], training loss: 0.0820
[1880/15000], training loss: 0.0807
16
AVD_Office_001_1_traj3, ate: 148.31754890048842
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1888/15000], training loss: 0.0890
[1896/15000], training loss: 0.0735
[1904/15000], training loss: 0.0659
[1912/15000], training loss: 0.0688
[1920/15000], training loss: 0.0778
16
AVD_Office_001_1_traj3, ate: 180.66379143950417
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1928/15000], training loss: 0.0788
[1936/15000], training loss: 0.0861
[1944/15000], training loss: 0.1022
[1952/15000], training loss: 0.0757
[1960/15000], training loss: 0.0720
16
AVD_Office_001_1_traj3, ate: 173.35870659055075
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[1968/15000], training loss: 0.0935
[1976/15000], training loss: 0.0903
[1984/15000], training loss: 0.0789
[1992/15000], training loss: 0.0996
[2000/15000], training loss: 0.0728
16
AVD_Office_001_1_traj3, ate: 182.07419992818637
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2008/15000], training loss: 0.0708
[2016/15000], training loss: 0.0973
[2024/15000], training loss: 0.0678
[2032/15000], training loss: 0.0756
[2040/15000], training loss: 0.0937
16
AVD_Office_001_1_traj3, ate: 160.68563171083287
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2048/15000], training loss: 0.0763
[2056/15000], training loss: 0.0645
[2064/15000], training loss: 0.0850
[2072/15000], training loss: 0.0997
[2080/15000], training loss: 0.0903
16
AVD_Office_001_1_traj3, ate: 141.19842782894614
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2088/15000], training loss: 0.1052
[2096/15000], training loss: 0.0871
[2104/15000], training loss: 0.0797
[2112/15000], training loss: 0.0648
[2120/15000], training loss: 0.0872
16
AVD_Office_001_1_traj3, ate: 168.4399822861363
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2128/15000], training loss: 0.0874
[2136/15000], training loss: 0.0868
[2144/15000], training loss: 0.0805
[2152/15000], training loss: 0.0857
[2160/15000], training loss: 0.0838
16
AVD_Office_001_1_traj3, ate: 188.87032159412547
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2168/15000], training loss: 0.0635
[2176/15000], training loss: 0.0726
[2184/15000], training loss: 0.0766
[2192/15000], training loss: 0.0699
[2200/15000], training loss: 0.0767
16
AVD_Office_001_1_traj3, ate: 152.51471370415604
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2208/15000], training loss: 0.0555
[2216/15000], training loss: 0.0651
[2224/15000], training loss: 0.0590
[2232/15000], training loss: 0.0683
[2240/15000], training loss: 0.0717
16
AVD_Office_001_1_traj3, ate: 163.1666096479098
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2248/15000], training loss: 0.0701
[2256/15000], training loss: 0.0825
[2264/15000], training loss: 0.0827
[2272/15000], training loss: 0.0589
[2280/15000], training loss: 0.0720
16
AVD_Office_001_1_traj3, ate: 181.73949896651143
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2288/15000], training loss: 0.0685
[2296/15000], training loss: 0.0996
[2304/15000], training loss: 0.0814
[2312/15000], training loss: 0.0619
[2320/15000], training loss: 0.0796
16
AVD_Office_001_1_traj3, ate: 170.03908731013138
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2328/15000], training loss: 0.0794
[2336/15000], training loss: 0.0705
[2344/15000], training loss: 0.0664
[2352/15000], training loss: 0.0736
[2360/15000], training loss: 0.0817
16
AVD_Office_001_1_traj3, ate: 165.81782088238762
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2368/15000], training loss: 0.0532
[2376/15000], training loss: 0.0915
[2384/15000], training loss: 0.0850
[2392/15000], training loss: 0.0771
[2400/15000], training loss: 0.0634
16
AVD_Office_001_1_traj3, ate: 170.21435517598908
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2408/15000], training loss: 0.0721
[2416/15000], training loss: 0.0606
[2424/15000], training loss: 0.0713
[2432/15000], training loss: 0.0757
[2440/15000], training loss: 0.0817
16
AVD_Office_001_1_traj3, ate: 172.47436864326116
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2448/15000], training loss: 0.0899
[2456/15000], training loss: 0.0710
[2464/15000], training loss: 0.0810
[2472/15000], training loss: 0.0630
[2480/15000], training loss: 0.0653
16
AVD_Office_001_1_traj3, ate: 165.34190613952347
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2488/15000], training loss: 0.0720
[2496/15000], training loss: 0.0761
[2504/15000], training loss: 0.0796
[2512/15000], training loss: 0.0752
[2520/15000], training loss: 0.0718
16
AVD_Office_001_1_traj3, ate: 168.13982776739613
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2528/15000], training loss: 0.0755
[2536/15000], training loss: 0.0759
[2544/15000], training loss: 0.0641
[2552/15000], training loss: 0.0738
[2560/15000], training loss: 0.0706
16
AVD_Office_001_1_traj3, ate: 140.7055359035726
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2568/15000], training loss: 0.0838
[2576/15000], training loss: 0.0609
[2584/15000], training loss: 0.0792
[2592/15000], training loss: 0.0788
[2600/15000], training loss: 0.0816
16
AVD_Office_001_1_traj3, ate: 145.79683542741628
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2608/15000], training loss: 0.0780
[2616/15000], training loss: 0.0763
[2624/15000], training loss: 0.0770
[2632/15000], training loss: 0.0744
[2640/15000], training loss: 0.0846
16
AVD_Office_001_1_traj3, ate: 152.27780319245582
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2648/15000], training loss: 0.0680
[2656/15000], training loss: 0.0808
[2664/15000], training loss: 0.0791
[2672/15000], training loss: 0.0754
[2680/15000], training loss: 0.0830
16
AVD_Office_001_1_traj3, ate: 149.2047716931849
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2688/15000], training loss: 0.0818
[2696/15000], training loss: 0.0798
[2704/15000], training loss: 0.0645
[2712/15000], training loss: 0.0954
[2720/15000], training loss: 0.1092
16
AVD_Office_001_1_traj3, ate: 164.54826489051902
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2728/15000], training loss: 0.0674
[2736/15000], training loss: 0.0729
[2744/15000], training loss: 0.0595
[2752/15000], training loss: 0.0996
[2760/15000], training loss: 0.0882
16
AVD_Office_001_1_traj3, ate: 177.55108384636193
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2768/15000], training loss: 0.0691
[2776/15000], training loss: 0.0721
[2784/15000], training loss: 0.0818
[2792/15000], training loss: 0.0760
[2800/15000], training loss: 0.0598
16
AVD_Office_001_1_traj3, ate: 157.05861400157622
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2808/15000], training loss: 0.0712
[2816/15000], training loss: 0.0529
[2824/15000], training loss: 0.0653
[2832/15000], training loss: 0.0785
[2840/15000], training loss: 0.0873
16
AVD_Office_001_1_traj3, ate: 160.96485520080824
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2848/15000], training loss: 0.0639
[2856/15000], training loss: 0.0616
[2864/15000], training loss: 0.0821
[2872/15000], training loss: 0.0733
[2880/15000], training loss: 0.0690
16
AVD_Office_001_1_traj3, ate: 156.5824422422561
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2888/15000], training loss: 0.0659
[2896/15000], training loss: 0.0988
[2904/15000], training loss: 0.0691
[2912/15000], training loss: 0.0568
[2920/15000], training loss: 0.1038
16
AVD_Office_001_1_traj3, ate: 167.33592424268915
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2928/15000], training loss: 0.1057
[2936/15000], training loss: 0.0687
[2944/15000], training loss: 0.0750
[2952/15000], training loss: 0.0751
[2960/15000], training loss: 0.0721
16
AVD_Office_001_1_traj3, ate: 157.9741371483422
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[2968/15000], training loss: 0.0777
[2976/15000], training loss: 0.0928
[2984/15000], training loss: 0.0689
[2992/15000], training loss: 0.0696
[3000/15000], training loss: 0.0672
16
AVD_Office_001_1_traj3, ate: 164.91992890468646
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3008/15000], training loss: 0.0652
[3016/15000], training loss: 0.0605
[3024/15000], training loss: 0.0686
[3032/15000], training loss: 0.0636
[3040/15000], training loss: 0.0724
16
AVD_Office_001_1_traj3, ate: 155.84565429692157
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3048/15000], training loss: 0.0597
[3056/15000], training loss: 0.0639
[3064/15000], training loss: 0.0854
[3072/15000], training loss: 0.0935
[3080/15000], training loss: 0.0810
16
AVD_Office_001_1_traj3, ate: 143.7675529189743
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3088/15000], training loss: 0.0833
[3096/15000], training loss: 0.0663
[3104/15000], training loss: 0.0737
[3112/15000], training loss: 0.0708
[3120/15000], training loss: 0.0710
16
AVD_Office_001_1_traj3, ate: 154.70173928599448
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3128/15000], training loss: 0.0607
[3136/15000], training loss: 0.0473
[3144/15000], training loss: 0.0740
[3152/15000], training loss: 0.0981
[3160/15000], training loss: 0.0713
16
AVD_Office_001_1_traj3, ate: 177.3044580330105
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3168/15000], training loss: 0.0688
[3176/15000], training loss: 0.0572
[3184/15000], training loss: 0.0895
[3192/15000], training loss: 0.0785
[3200/15000], training loss: 0.0683
16
AVD_Office_001_1_traj3, ate: 152.39470307984251
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3208/15000], training loss: 0.0594
[3216/15000], training loss: 0.1073
[3224/15000], training loss: 0.0940
[3232/15000], training loss: 0.0855
[3240/15000], training loss: 0.0731
16
AVD_Office_001_1_traj3, ate: 159.6794792720518
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3248/15000], training loss: 0.0644
[3256/15000], training loss: 0.0626
[3264/15000], training loss: 0.0769
[3272/15000], training loss: 0.0840
[3280/15000], training loss: 0.0553
16
AVD_Office_001_1_traj3, ate: 137.89844968370446
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3288/15000], training loss: 0.0634
[3296/15000], training loss: 0.0777
[3304/15000], training loss: 0.0626
[3312/15000], training loss: 0.0696
[3320/15000], training loss: 0.0605
16
AVD_Office_001_1_traj3, ate: 160.99487224103842
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3328/15000], training loss: 0.0751
[3336/15000], training loss: 0.0632
[3344/15000], training loss: 0.0788
[3352/15000], training loss: 0.0771
[3360/15000], training loss: 0.0812
16
AVD_Office_001_1_traj3, ate: 130.50120317024442
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3368/15000], training loss: 0.0808
[3376/15000], training loss: 0.0596
[3384/15000], training loss: 0.0767
[3392/15000], training loss: 0.0865
[3400/15000], training loss: 0.0741
16
AVD_Office_001_1_traj3, ate: 135.98744345112064
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3408/15000], training loss: 0.0640
[3416/15000], training loss: 0.0800
[3424/15000], training loss: 0.0719
[3432/15000], training loss: 0.0818
[3440/15000], training loss: 0.0788
16
AVD_Office_001_1_traj3, ate: 120.81709992944087
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3448/15000], training loss: 0.0821
[3456/15000], training loss: 0.0991
[3464/15000], training loss: 0.0750
[3472/15000], training loss: 0.0906
[3480/15000], training loss: 0.0602
16
AVD_Office_001_1_traj3, ate: 152.0801073704076
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3488/15000], training loss: 0.0743
[3496/15000], training loss: 0.0842
[3504/15000], training loss: 0.0795
[3512/15000], training loss: 0.0701
[3520/15000], training loss: 0.0603
16
AVD_Office_001_1_traj3, ate: 175.2328932327602
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3528/15000], training loss: 0.0691
[3536/15000], training loss: 0.0624
[3544/15000], training loss: 0.0811
[3552/15000], training loss: 0.0732
[3560/15000], training loss: 0.0840
16
AVD_Office_001_1_traj3, ate: 129.89959147784404
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3568/15000], training loss: 0.0648
[3576/15000], training loss: 0.0710
[3584/15000], training loss: 0.0662
[3592/15000], training loss: 0.0752
[3600/15000], training loss: 0.0767
16
AVD_Office_001_1_traj3, ate: 130.24109968369353
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3608/15000], training loss: 0.0743
[3616/15000], training loss: 0.0644
[3624/15000], training loss: 0.0750
[3632/15000], training loss: 0.0717
[3640/15000], training loss: 0.0769
16
AVD_Office_001_1_traj3, ate: 138.42396882160276
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3648/15000], training loss: 0.0743
[3656/15000], training loss: 0.0825
[3664/15000], training loss: 0.0768
[3672/15000], training loss: 0.0750
[3680/15000], training loss: 0.0744
16
AVD_Office_001_1_traj3, ate: 140.70807175303057
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3688/15000], training loss: 0.0623
[3696/15000], training loss: 0.0728
[3704/15000], training loss: 0.0791
[3712/15000], training loss: 0.0834
[3720/15000], training loss: 0.0777
16
AVD_Office_001_1_traj3, ate: 129.09554247706936
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3728/15000], training loss: 0.0666
[3736/15000], training loss: 0.0633
[3744/15000], training loss: 0.0638
[3752/15000], training loss: 0.0584
[3760/15000], training loss: 0.0636
16
AVD_Office_001_1_traj3, ate: 143.98497531054394
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3768/15000], training loss: 0.0801
[3776/15000], training loss: 0.0584
[3784/15000], training loss: 0.0633
[3792/15000], training loss: 0.0621
[3800/15000], training loss: 0.0691
16
AVD_Office_001_1_traj3, ate: 132.75663699796655
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3808/15000], training loss: 0.0697
[3816/15000], training loss: 0.0716
[3824/15000], training loss: 0.0690
[3832/15000], training loss: 0.0605
[3840/15000], training loss: 0.0818
16
AVD_Office_001_1_traj3, ate: 140.40722839473918
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3848/15000], training loss: 0.0711
[3856/15000], training loss: 0.0693
[3864/15000], training loss: 0.0592
[3872/15000], training loss: 0.0908
[3880/15000], training loss: 0.0867
16
AVD_Office_001_1_traj3, ate: 142.37225736688245
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3888/15000], training loss: 0.0535
[3896/15000], training loss: 0.0597
[3904/15000], training loss: 0.0793
[3912/15000], training loss: 0.0659
[3920/15000], training loss: 0.0966
16
AVD_Office_001_1_traj3, ate: 133.92617611344087
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3928/15000], training loss: 0.0793
[3936/15000], training loss: 0.0791
[3944/15000], training loss: 0.0945
[3952/15000], training loss: 0.0639
[3960/15000], training loss: 0.0571
16
AVD_Office_001_1_traj3, ate: 143.97434525354825
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[3968/15000], training loss: 0.0738
[3976/15000], training loss: 0.0816
[3984/15000], training loss: 0.0657
[3992/15000], training loss: 0.0579
[4000/15000], training loss: 0.0700
16
AVD_Office_001_1_traj3, ate: 141.21475463744002
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4008/15000], training loss: 0.0625
[4016/15000], training loss: 0.0752
[4024/15000], training loss: 0.0744
[4032/15000], training loss: 0.0718
[4040/15000], training loss: 0.0705
16
AVD_Office_001_1_traj3, ate: 131.42461521261058
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4048/15000], training loss: 0.0603
[4056/15000], training loss: 0.0727
[4064/15000], training loss: 0.0630
[4072/15000], training loss: 0.0848
[4080/15000], training loss: 0.0539
16
AVD_Office_001_1_traj3, ate: 141.21248007877358
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4088/15000], training loss: 0.0638
[4096/15000], training loss: 0.0542
[4104/15000], training loss: 0.0739
[4112/15000], training loss: 0.0754
[4120/15000], training loss: 0.0821
16
AVD_Office_001_1_traj3, ate: 130.1039583209289
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4128/15000], training loss: 0.0602
[4136/15000], training loss: 0.0631
[4144/15000], training loss: 0.0739
[4152/15000], training loss: 0.0845
[4160/15000], training loss: 0.0724
16
AVD_Office_001_1_traj3, ate: 133.7454283543072
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4168/15000], training loss: 0.0649
[4176/15000], training loss: 0.0700
[4184/15000], training loss: 0.0709
[4192/15000], training loss: 0.0547
[4200/15000], training loss: 0.0686
16
AVD_Office_001_1_traj3, ate: 147.12524902500357
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4208/15000], training loss: 0.0738
[4216/15000], training loss: 0.0608
[4224/15000], training loss: 0.0736
[4232/15000], training loss: 0.0775
[4240/15000], training loss: 0.0522
16
AVD_Office_001_1_traj3, ate: 144.32352955607735
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4248/15000], training loss: 0.1564
[4256/15000], training loss: 0.0851
[4264/15000], training loss: 0.0817
[4272/15000], training loss: 0.0873
[4280/15000], training loss: 0.1136
16
AVD_Office_001_1_traj3, ate: 132.53647245732608
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4288/15000], training loss: 0.0678
[4296/15000], training loss: 0.0789
[4304/15000], training loss: 0.0775
[4312/15000], training loss: 0.0776
[4320/15000], training loss: 0.0754
16
AVD_Office_001_1_traj3, ate: 130.7499779582584
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4328/15000], training loss: 0.0732
[4336/15000], training loss: 0.0756
[4344/15000], training loss: 0.0789
[4352/15000], training loss: 0.0668
[4360/15000], training loss: 0.0635
16
AVD_Office_001_1_traj3, ate: 141.78546066139754
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4368/15000], training loss: 0.0776
[4376/15000], training loss: 0.0642
[4384/15000], training loss: 0.0637
[4392/15000], training loss: 0.0633
[4400/15000], training loss: 0.0648
16
AVD_Office_001_1_traj3, ate: 129.81904246437716
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4408/15000], training loss: 0.0754
[4416/15000], training loss: 0.0650
[4424/15000], training loss: 0.0639
[4432/15000], training loss: 0.0676
[4440/15000], training loss: 0.0881
16
AVD_Office_001_1_traj3, ate: 130.16250645911967
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4448/15000], training loss: 0.0639
[4456/15000], training loss: 0.0688
[4464/15000], training loss: 0.1150
[4472/15000], training loss: 0.0746
[4480/15000], training loss: 0.0829
16
AVD_Office_001_1_traj3, ate: 126.83196131481132
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4488/15000], training loss: 0.0734
[4496/15000], training loss: 0.1078
[4504/15000], training loss: 0.1018
[4512/15000], training loss: 0.0716
[4520/15000], training loss: 0.0665
16
AVD_Office_001_1_traj3, ate: 136.9370630971605
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4528/15000], training loss: 0.0615
[4536/15000], training loss: 0.0618
[4544/15000], training loss: 0.0758
[4552/15000], training loss: 0.0551
[4560/15000], training loss: 0.0920
16
AVD_Office_001_1_traj3, ate: 116.17387969382088
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4568/15000], training loss: 0.0753
[4576/15000], training loss: 0.0785
[4584/15000], training loss: 0.0831
[4592/15000], training loss: 0.0587
[4600/15000], training loss: 0.0677
16
AVD_Office_001_1_traj3, ate: 139.18446873049086
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4608/15000], training loss: 0.0643
[4616/15000], training loss: 0.0597
[4624/15000], training loss: 0.0653
[4632/15000], training loss: 0.0744
[4640/15000], training loss: 0.0764
16
AVD_Office_001_1_traj3, ate: 143.17308686346638
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4648/15000], training loss: 0.0826
[4656/15000], training loss: 0.0706
[4664/15000], training loss: 0.0830
[4672/15000], training loss: 0.0669
[4680/15000], training loss: 0.0727
16
AVD_Office_001_1_traj3, ate: 123.80254612531395
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4688/15000], training loss: 0.0862
[4696/15000], training loss: 0.0790
[4704/15000], training loss: 0.0700
[4712/15000], training loss: 0.0509
[4720/15000], training loss: 0.0428
16
AVD_Office_001_1_traj3, ate: 140.0430615184083
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4728/15000], training loss: 0.0748
[4736/15000], training loss: 0.0960
[4744/15000], training loss: 0.0622
[4752/15000], training loss: 0.0665
[4760/15000], training loss: 0.0858
16
AVD_Office_001_1_traj3, ate: 123.77296024102628
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4768/15000], training loss: 0.0631
[4776/15000], training loss: 0.0483
[4784/15000], training loss: 0.0882
[4792/15000], training loss: 0.0720
[4800/15000], training loss: 0.0738
16
AVD_Office_001_1_traj3, ate: 129.6744159138101
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4808/15000], training loss: 0.0694
[4816/15000], training loss: 0.0756
[4824/15000], training loss: 0.0946
[4832/15000], training loss: 0.0657
[4840/15000], training loss: 0.0755
16
AVD_Office_001_1_traj3, ate: 129.38630818961786
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4848/15000], training loss: 0.0834
[4856/15000], training loss: 0.0690
[4864/15000], training loss: 0.0523
[4872/15000], training loss: 0.0788
[4880/15000], training loss: 0.0724
16
AVD_Office_001_1_traj3, ate: 126.61568340181931
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4888/15000], training loss: 0.0763
[4896/15000], training loss: 0.0566
[4904/15000], training loss: 0.0592
[4912/15000], training loss: 0.0604
[4920/15000], training loss: 0.0604
16
AVD_Office_001_1_traj3, ate: 128.6502725188025
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4928/15000], training loss: 0.0919
[4936/15000], training loss: 0.0644
[4944/15000], training loss: 0.0910
[4952/15000], training loss: 0.0590
[4960/15000], training loss: 0.0602
16
AVD_Office_001_1_traj3, ate: 122.32320546528325
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[4968/15000], training loss: 0.0711
[4976/15000], training loss: 0.0924
[4984/15000], training loss: 0.0667
[4992/15000], training loss: 0.0465
[5000/15000], training loss: 0.0898
16
AVD_Office_001_1_traj3, ate: 129.15275942095215
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5008/15000], training loss: 0.0762
[5016/15000], training loss: 0.0713
[5024/15000], training loss: 0.0760
[5032/15000], training loss: 0.0546
[5040/15000], training loss: 0.0591
16
AVD_Office_001_1_traj3, ate: 133.86175162560767
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5048/15000], training loss: 0.0974
[5056/15000], training loss: 0.0814
[5064/15000], training loss: 0.0614
[5072/15000], training loss: 0.0590
[5080/15000], training loss: 0.0643
16
AVD_Office_001_1_traj3, ate: 128.79695902739243
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5088/15000], training loss: 0.0618
[5096/15000], training loss: 0.0589
[5104/15000], training loss: 0.0518
[5112/15000], training loss: 0.0915
[5120/15000], training loss: 0.0828
16
AVD_Office_001_1_traj3, ate: 122.25663394367497
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5128/15000], training loss: 0.0745
[5136/15000], training loss: 0.0856
[5144/15000], training loss: 0.0611
[5152/15000], training loss: 0.0658
[5160/15000], training loss: 0.0750
16
AVD_Office_001_1_traj3, ate: 131.68537514120385
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5168/15000], training loss: 0.0601
[5176/15000], training loss: 0.0718
[5184/15000], training loss: 0.0762
[5192/15000], training loss: 0.0851
[5200/15000], training loss: 0.0736
16
AVD_Office_001_1_traj3, ate: 118.42456987948641
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5208/15000], training loss: 0.0913
[5216/15000], training loss: 0.0644
[5224/15000], training loss: 0.0920
[5232/15000], training loss: 0.0488
[5240/15000], training loss: 0.0794
16
AVD_Office_001_1_traj3, ate: 137.0540655101154
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5248/15000], training loss: 0.0685
[5256/15000], training loss: 0.0580
[5264/15000], training loss: 0.0630
[5272/15000], training loss: 0.0853
[5280/15000], training loss: 0.0757
16
AVD_Office_001_1_traj3, ate: 115.14464637684617
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5288/15000], training loss: 0.0680
[5296/15000], training loss: 0.0740
[5304/15000], training loss: 0.1208
[5312/15000], training loss: 0.0483
[5320/15000], training loss: 0.0791
16
AVD_Office_001_1_traj3, ate: 112.22850220707925
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5328/15000], training loss: 0.0900
[5336/15000], training loss: 0.0749
[5344/15000], training loss: 0.0582
[5352/15000], training loss: 0.0809
[5360/15000], training loss: 0.0814
16
AVD_Office_001_1_traj3, ate: 99.91537691351624
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5368/15000], training loss: 0.0844
[5376/15000], training loss: 0.0620
[5384/15000], training loss: 0.0866
[5392/15000], training loss: 0.0558
[5400/15000], training loss: 0.0748
16
AVD_Office_001_1_traj3, ate: 118.93413353659052
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5408/15000], training loss: 0.0823
[5416/15000], training loss: 0.0668
[5424/15000], training loss: 0.0978
[5432/15000], training loss: 0.0501
[5440/15000], training loss: 0.0637
16
AVD_Office_001_1_traj3, ate: 129.27613592950735
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5448/15000], training loss: 0.0880
[5456/15000], training loss: 0.0755
[5464/15000], training loss: 0.0793
[5472/15000], training loss: 0.0588
[5480/15000], training loss: 0.0830
16
AVD_Office_001_1_traj3, ate: 103.93309848041366
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5488/15000], training loss: 0.0757
[5496/15000], training loss: 0.0684
[5504/15000], training loss: 0.0780
[5512/15000], training loss: 0.0589
[5520/15000], training loss: 0.0698
16
AVD_Office_001_1_traj3, ate: 111.24148156945716
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5528/15000], training loss: 0.0786
[5536/15000], training loss: 0.0735
[5544/15000], training loss: 0.0524
[5552/15000], training loss: 0.0667
[5560/15000], training loss: 0.0783
16
AVD_Office_001_1_traj3, ate: 110.57299677209922
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5568/15000], training loss: 0.0658
[5576/15000], training loss: 0.0672
[5584/15000], training loss: 0.0707
[5592/15000], training loss: 0.0757
[5600/15000], training loss: 0.0629
16
AVD_Office_001_1_traj3, ate: 118.79453273667193
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5608/15000], training loss: 0.0560
[5616/15000], training loss: 0.0485
[5624/15000], training loss: 0.0913
[5632/15000], training loss: 0.0750
[5640/15000], training loss: 0.0578
16
AVD_Office_001_1_traj3, ate: 110.18229472489104
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5648/15000], training loss: 0.0663
[5656/15000], training loss: 0.0789
[5664/15000], training loss: 0.0872
[5672/15000], training loss: 0.0854
[5680/15000], training loss: 0.0561
16
AVD_Office_001_1_traj3, ate: 101.36289744716812
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5688/15000], training loss: 0.0631
[5696/15000], training loss: 0.0812
[5704/15000], training loss: 0.0627
[5712/15000], training loss: 0.0728
[5720/15000], training loss: 0.0680
16
AVD_Office_001_1_traj3, ate: 119.60873593617546
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5728/15000], training loss: 0.0627
[5736/15000], training loss: 0.0655
[5744/15000], training loss: 0.0696
[5752/15000], training loss: 0.0740
[5760/15000], training loss: 0.0581
16
AVD_Office_001_1_traj3, ate: 114.26015618568351
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5768/15000], training loss: 0.0792
[5776/15000], training loss: 0.0708
[5784/15000], training loss: 0.0628
[5792/15000], training loss: 0.0587
[5800/15000], training loss: 0.0692
16
AVD_Office_001_1_traj3, ate: 116.46634941129227
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5808/15000], training loss: 0.0658
[5816/15000], training loss: 0.0839
[5824/15000], training loss: 0.0503
[5832/15000], training loss: 0.0608
[5840/15000], training loss: 0.0560
16
AVD_Office_001_1_traj3, ate: 130.4889000894857
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5848/15000], training loss: 0.0650
[5856/15000], training loss: 0.0631
[5864/15000], training loss: 0.1213
[5872/15000], training loss: 0.0678
[5880/15000], training loss: 0.0556
16
AVD_Office_001_1_traj3, ate: 118.04863057287861
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5888/15000], training loss: 0.0506
[5896/15000], training loss: 0.0600
[5904/15000], training loss: 0.0547
[5912/15000], training loss: 0.0553
[5920/15000], training loss: 0.0630
16
AVD_Office_001_1_traj3, ate: 123.63257234440107
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5928/15000], training loss: 0.0827
[5936/15000], training loss: 0.1092
[5944/15000], training loss: 0.0778
[5952/15000], training loss: 0.0750
[5960/15000], training loss: 0.0871
16
AVD_Office_001_1_traj3, ate: 118.57553156289329
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[5968/15000], training loss: 0.0701
[5976/15000], training loss: 0.0760
[5984/15000], training loss: 0.0615
[5992/15000], training loss: 0.0555
[6000/15000], training loss: 0.0591
16
AVD_Office_001_1_traj3, ate: 114.21086595353655
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6008/15000], training loss: 0.0494
[6016/15000], training loss: 0.0729
[6024/15000], training loss: 0.0784
[6032/15000], training loss: 0.0665
[6040/15000], training loss: 0.0784
16
AVD_Office_001_1_traj3, ate: 104.30730323448824
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6048/15000], training loss: 0.0933
[6056/15000], training loss: 0.0568
[6064/15000], training loss: 0.0718
[6072/15000], training loss: 0.0648
[6080/15000], training loss: 0.0670
16
AVD_Office_001_1_traj3, ate: 119.2245147829765
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6088/15000], training loss: 0.0628
[6096/15000], training loss: 0.0527
[6104/15000], training loss: 0.0633
[6112/15000], training loss: 0.0674
[6120/15000], training loss: 0.0776
16
AVD_Office_001_1_traj3, ate: 101.51674403995108
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6128/15000], training loss: 0.0913
[6136/15000], training loss: 0.0633
[6144/15000], training loss: 0.0760
[6152/15000], training loss: 0.0537
[6160/15000], training loss: 0.0722
16
AVD_Office_001_1_traj3, ate: 117.25984367905156
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6168/15000], training loss: 0.0567
[6176/15000], training loss: 0.0531
[6184/15000], training loss: 0.0611
[6192/15000], training loss: 0.0790
[6200/15000], training loss: 0.0611
16
AVD_Office_001_1_traj3, ate: 116.25502921041253
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6208/15000], training loss: 0.0745
[6216/15000], training loss: 0.0496
[6224/15000], training loss: 0.0534
[6232/15000], training loss: 0.0697
[6240/15000], training loss: 0.0596
16
AVD_Office_001_1_traj3, ate: 113.77239026604421
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6248/15000], training loss: 0.0725
[6256/15000], training loss: 0.0717
[6264/15000], training loss: 0.0534
[6272/15000], training loss: 0.0568
[6280/15000], training loss: 0.0828
16
AVD_Office_001_1_traj3, ate: 105.79240107391779
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6288/15000], training loss: 0.0946
[6296/15000], training loss: 0.0714
[6304/15000], training loss: 0.0473
[6312/15000], training loss: 0.0751
[6320/15000], training loss: 0.0742
16
AVD_Office_001_1_traj3, ate: 113.20484080653739
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6328/15000], training loss: 0.0543
[6336/15000], training loss: 0.0857
[6344/15000], training loss: 0.0730
[6352/15000], training loss: 0.0682
[6360/15000], training loss: 0.0523
16
AVD_Office_001_1_traj3, ate: 117.7548832156506
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6368/15000], training loss: 0.0619
[6376/15000], training loss: 0.0560
[6384/15000], training loss: 0.0608
[6392/15000], training loss: 0.0721
[6400/15000], training loss: 0.0531
16
AVD_Office_001_1_traj3, ate: 107.35277624527797
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6408/15000], training loss: 0.0674
[6416/15000], training loss: 0.0929
[6424/15000], training loss: 0.0596
[6432/15000], training loss: 0.0728
[6440/15000], training loss: 0.0667
16
AVD_Office_001_1_traj3, ate: 116.61329816585814
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6448/15000], training loss: 0.0480
[6456/15000], training loss: 0.0629
[6464/15000], training loss: 0.0713
[6472/15000], training loss: 0.0863
[6480/15000], training loss: 0.0677
16
AVD_Office_001_1_traj3, ate: 126.85864491550288
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6488/15000], training loss: 0.0667
[6496/15000], training loss: 0.0559
[6504/15000], training loss: 0.0669
[6512/15000], training loss: 0.0794
[6520/15000], training loss: 0.0683
16
AVD_Office_001_1_traj3, ate: 111.46450570269091
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6528/15000], training loss: 0.0770
[6536/15000], training loss: 0.0542
[6544/15000], training loss: 0.0903
[6552/15000], training loss: 0.0466
[6560/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 121.16814548367121
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6568/15000], training loss: 0.0872
[6576/15000], training loss: 0.0705
[6584/15000], training loss: 0.0607
[6592/15000], training loss: 0.0863
[6600/15000], training loss: 0.0707
16
AVD_Office_001_1_traj3, ate: 113.91259168111296
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6608/15000], training loss: 0.0568
[6616/15000], training loss: 0.0650
[6624/15000], training loss: 0.0626
[6632/15000], training loss: 0.0753
[6640/15000], training loss: 0.0479
16
AVD_Office_001_1_traj3, ate: 116.27568332069278
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6648/15000], training loss: 0.0853
[6656/15000], training loss: 0.0614
[6664/15000], training loss: 0.0490
[6672/15000], training loss: 0.0533
[6680/15000], training loss: 0.0681
16
AVD_Office_001_1_traj3, ate: 114.86427848928398
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6688/15000], training loss: 0.0655
[6696/15000], training loss: 0.0515
[6704/15000], training loss: 0.0660
[6712/15000], training loss: 0.0700
[6720/15000], training loss: 0.0843
16
AVD_Office_001_1_traj3, ate: 110.80084400957844
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6728/15000], training loss: 0.0872
[6736/15000], training loss: 0.0853
[6744/15000], training loss: 0.0706
[6752/15000], training loss: 0.0611
[6760/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 123.60887114085116
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6768/15000], training loss: 0.0767
[6776/15000], training loss: 0.0984
[6784/15000], training loss: 0.0659
[6792/15000], training loss: 0.0536
[6800/15000], training loss: 0.0793
16
AVD_Office_001_1_traj3, ate: 124.6619121400516
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6808/15000], training loss: 0.0670
[6816/15000], training loss: 0.0497
[6824/15000], training loss: 0.0555
[6832/15000], training loss: 0.0659
[6840/15000], training loss: 0.0620
16
AVD_Office_001_1_traj3, ate: 115.85611772568636
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6848/15000], training loss: 0.0595
[6856/15000], training loss: 0.0658
[6864/15000], training loss: 0.0771
[6872/15000], training loss: 0.0588
[6880/15000], training loss: 0.0711
16
AVD_Office_001_1_traj3, ate: 113.52379205425602
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6888/15000], training loss: 0.0764
[6896/15000], training loss: 0.0632
[6904/15000], training loss: 0.0598
[6912/15000], training loss: 0.0708
[6920/15000], training loss: 0.0738
16
AVD_Office_001_1_traj3, ate: 116.06805876176146
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6928/15000], training loss: 0.0636
[6936/15000], training loss: 0.0543
[6944/15000], training loss: 0.0465
[6952/15000], training loss: 0.0537
[6960/15000], training loss: 0.0706
16
AVD_Office_001_1_traj3, ate: 105.13219187700066
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[6968/15000], training loss: 0.0619
[6976/15000], training loss: 0.0670
[6984/15000], training loss: 0.0655
[6992/15000], training loss: 0.0752
[7000/15000], training loss: 0.0888
16
AVD_Office_001_1_traj3, ate: 104.01696601964615
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7008/15000], training loss: 0.0659
[7016/15000], training loss: 0.0540
[7024/15000], training loss: 0.0614
[7032/15000], training loss: 0.0490
[7040/15000], training loss: 0.0699
16
AVD_Office_001_1_traj3, ate: 117.14129285916059
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7048/15000], training loss: 0.0666
[7056/15000], training loss: 0.0636
[7064/15000], training loss: 0.0726
[7072/15000], training loss: 0.0575
[7080/15000], training loss: 0.0636
16
AVD_Office_001_1_traj3, ate: 101.42885721364138
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7088/15000], training loss: 0.0819
[7096/15000], training loss: 0.0829
[7104/15000], training loss: 0.0973
[7112/15000], training loss: 0.0650
[7120/15000], training loss: 0.0462
16
AVD_Office_001_1_traj3, ate: 118.47887467197786
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7128/15000], training loss: 0.0643
[7136/15000], training loss: 0.0898
[7144/15000], training loss: 0.0765
[7152/15000], training loss: 0.0569
[7160/15000], training loss: 0.0570
16
AVD_Office_001_1_traj3, ate: 110.46126376877426
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7168/15000], training loss: 0.0677
[7176/15000], training loss: 0.0697
[7184/15000], training loss: 0.0617
[7192/15000], training loss: 0.0770
[7200/15000], training loss: 0.0470
16
AVD_Office_001_1_traj3, ate: 121.69840772258853
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7208/15000], training loss: 0.0589
[7216/15000], training loss: 0.0559
[7224/15000], training loss: 0.0764
[7232/15000], training loss: 0.0605
[7240/15000], training loss: 0.0591
16
AVD_Office_001_1_traj3, ate: 127.76039732213913
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7248/15000], training loss: 0.0641
[7256/15000], training loss: 0.0587
[7264/15000], training loss: 0.0591
[7272/15000], training loss: 0.0672
[7280/15000], training loss: 0.0784
16
AVD_Office_001_1_traj3, ate: 102.76920297105174
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7288/15000], training loss: 0.0755
[7296/15000], training loss: 0.0515
[7304/15000], training loss: 0.0795
[7312/15000], training loss: 0.0751
[7320/15000], training loss: 0.0792
16
AVD_Office_001_1_traj3, ate: 112.19875957816866
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7328/15000], training loss: 0.0744
[7336/15000], training loss: 0.0643
[7344/15000], training loss: 0.0530
[7352/15000], training loss: 0.0656
[7360/15000], training loss: 0.0657
16
AVD_Office_001_1_traj3, ate: 123.33618187634185
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7368/15000], training loss: 0.0806
[7376/15000], training loss: 0.0780
[7384/15000], training loss: 0.0643
[7392/15000], training loss: 0.0633
[7400/15000], training loss: 0.0604
16
AVD_Office_001_1_traj3, ate: 119.1173046152965
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7408/15000], training loss: 0.0489
[7416/15000], training loss: 0.0453
[7424/15000], training loss: 0.0695
[7432/15000], training loss: 0.0736
[7440/15000], training loss: 0.0833
16
AVD_Office_001_1_traj3, ate: 125.94038936784756
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7448/15000], training loss: 0.0971
[7456/15000], training loss: 0.0653
[7464/15000], training loss: 0.0691
[7472/15000], training loss: 0.0684
[7480/15000], training loss: 0.0610
16
AVD_Office_001_1_traj3, ate: 126.54379313432888
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7488/15000], training loss: 0.0679
[7496/15000], training loss: 0.0643
[7504/15000], training loss: 0.0649
[7512/15000], training loss: 0.0527
[7520/15000], training loss: 0.0602
16
AVD_Office_001_1_traj3, ate: 117.41035888584751
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7528/15000], training loss: 0.0716
[7536/15000], training loss: 0.0676
[7544/15000], training loss: 0.0815
[7552/15000], training loss: 0.0753
[7560/15000], training loss: 0.0723
16
AVD_Office_001_1_traj3, ate: 115.81696736753952
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7568/15000], training loss: 0.0798
[7576/15000], training loss: 0.0757
[7584/15000], training loss: 0.0664
[7592/15000], training loss: 0.0588
[7600/15000], training loss: 0.0609
16
AVD_Office_001_1_traj3, ate: 111.5489581549178
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7608/15000], training loss: 0.0612
[7616/15000], training loss: 0.0638
[7624/15000], training loss: 0.0646
[7632/15000], training loss: 0.0750
[7640/15000], training loss: 0.0831
16
AVD_Office_001_1_traj3, ate: 105.69815241848771
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7648/15000], training loss: 0.0637
[7656/15000], training loss: 0.0679
[7664/15000], training loss: 0.0716
[7672/15000], training loss: 0.0663
[7680/15000], training loss: 0.0632
16
AVD_Office_001_1_traj3, ate: 102.68795058319618
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7688/15000], training loss: 0.0936
[7696/15000], training loss: 0.0671
[7704/15000], training loss: 0.0724
[7712/15000], training loss: 0.0638
[7720/15000], training loss: 0.0603
16
AVD_Office_001_1_traj3, ate: 116.71415580039462
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7728/15000], training loss: 0.0649
[7736/15000], training loss: 0.0637
[7744/15000], training loss: 0.0469
[7752/15000], training loss: 0.0651
[7760/15000], training loss: 0.0663
16
AVD_Office_001_1_traj3, ate: 110.01550981934696
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7768/15000], training loss: 0.1039
[7776/15000], training loss: 0.0631
[7784/15000], training loss: 0.0526
[7792/15000], training loss: 0.0833
[7800/15000], training loss: 0.0533
16
AVD_Office_001_1_traj3, ate: 111.6148745267813
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7808/15000], training loss: 0.0698
[7816/15000], training loss: 0.0913
[7824/15000], training loss: 0.0621
[7832/15000], training loss: 0.0610
[7840/15000], training loss: 0.0723
16
AVD_Office_001_1_traj3, ate: 97.78835330999682
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7848/15000], training loss: 0.0474
[7856/15000], training loss: 0.0747
[7864/15000], training loss: 0.0840
[7872/15000], training loss: 0.0670
[7880/15000], training loss: 0.0559
16
AVD_Office_001_1_traj3, ate: 100.43983590532865
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7888/15000], training loss: 0.0676
[7896/15000], training loss: 0.0745
[7904/15000], training loss: 0.0692
[7912/15000], training loss: 0.0473
[7920/15000], training loss: 0.0976
16
AVD_Office_001_1_traj3, ate: 112.03474916195233
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7928/15000], training loss: 0.0566
[7936/15000], training loss: 0.0879
[7944/15000], training loss: 0.0727
[7952/15000], training loss: 0.0671
[7960/15000], training loss: 0.0642
16
AVD_Office_001_1_traj3, ate: 113.25279854635963
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[7968/15000], training loss: 0.1057
[7976/15000], training loss: 0.0556
[7984/15000], training loss: 0.0527
[7992/15000], training loss: 0.0756
[8000/15000], training loss: 0.0528
16
AVD_Office_001_1_traj3, ate: 110.1762146507078
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8008/15000], training loss: 0.0703
[8016/15000], training loss: 0.0633
[8024/15000], training loss: 0.0580
[8032/15000], training loss: 0.0691
[8040/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 111.31663197202815
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8048/15000], training loss: 0.0598
[8056/15000], training loss: 0.0675
[8064/15000], training loss: 0.0686
[8072/15000], training loss: 0.0509
[8080/15000], training loss: 0.0605
16
AVD_Office_001_1_traj3, ate: 117.09457543486796
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8088/15000], training loss: 0.0711
[8096/15000], training loss: 0.0539
[8104/15000], training loss: 0.0813
[8112/15000], training loss: 0.0668
[8120/15000], training loss: 0.0932
16
AVD_Office_001_1_traj3, ate: 117.64676754901772
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8128/15000], training loss: 0.0703
[8136/15000], training loss: 0.0756
[8144/15000], training loss: 0.0623
[8152/15000], training loss: 0.0634
[8160/15000], training loss: 0.0729
16
AVD_Office_001_1_traj3, ate: 111.13049898947371
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8168/15000], training loss: 0.0927
[8176/15000], training loss: 0.0637
[8184/15000], training loss: 0.0733
[8192/15000], training loss: 0.0840
[8200/15000], training loss: 0.0554
16
AVD_Office_001_1_traj3, ate: 122.7605039277512
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8208/15000], training loss: 0.0620
[8216/15000], training loss: 0.0522
[8224/15000], training loss: 0.0510
[8232/15000], training loss: 0.0570
[8240/15000], training loss: 0.0887
16
AVD_Office_001_1_traj3, ate: 118.28228616437029
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8248/15000], training loss: 0.0570
[8256/15000], training loss: 0.0602
[8264/15000], training loss: 0.0578
[8272/15000], training loss: 0.0669
[8280/15000], training loss: 0.0659
16
AVD_Office_001_1_traj3, ate: 99.48711924107144
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8288/15000], training loss: 0.0604
[8296/15000], training loss: 0.0715
[8304/15000], training loss: 0.0472
[8312/15000], training loss: 0.0896
[8320/15000], training loss: 0.0704
16
AVD_Office_001_1_traj3, ate: 119.46973799915503
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8328/15000], training loss: 0.0797
[8336/15000], training loss: 0.0626
[8344/15000], training loss: 0.0805
[8352/15000], training loss: 0.0517
[8360/15000], training loss: 0.0612
16
AVD_Office_001_1_traj3, ate: 116.3535140459854
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8368/15000], training loss: 0.0651
[8376/15000], training loss: 0.0534
[8384/15000], training loss: 0.0901
[8392/15000], training loss: 0.0764
[8400/15000], training loss: 0.0478
16
AVD_Office_001_1_traj3, ate: 126.8283047228091
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8408/15000], training loss: 0.0709
[8416/15000], training loss: 0.0615
[8424/15000], training loss: 0.0592
[8432/15000], training loss: 0.0689
[8440/15000], training loss: 0.0538
16
AVD_Office_001_1_traj3, ate: 122.46417865460968
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8448/15000], training loss: 0.0693
[8456/15000], training loss: 0.0479
[8464/15000], training loss: 0.0490
[8472/15000], training loss: 0.0719
[8480/15000], training loss: 0.0708
16
AVD_Office_001_1_traj3, ate: 109.91922072274663
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8488/15000], training loss: 0.0738
[8496/15000], training loss: 0.0596
[8504/15000], training loss: 0.0646
[8512/15000], training loss: 0.0441
[8520/15000], training loss: 0.0971
16
AVD_Office_001_1_traj3, ate: 122.67240674334894
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8528/15000], training loss: 0.0638
[8536/15000], training loss: 0.0505
[8544/15000], training loss: 0.0500
[8552/15000], training loss: 0.0679
[8560/15000], training loss: 0.0671
16
AVD_Office_001_1_traj3, ate: 104.9223228856324
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8568/15000], training loss: 0.0468
[8576/15000], training loss: 0.0856
[8584/15000], training loss: 0.0549
[8592/15000], training loss: 0.0662
[8600/15000], training loss: 0.0632
16
AVD_Office_001_1_traj3, ate: 103.57854301427128
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8608/15000], training loss: 0.0584
[8616/15000], training loss: 0.0571
[8624/15000], training loss: 0.0523
[8632/15000], training loss: 0.0624
[8640/15000], training loss: 0.0604
16
AVD_Office_001_1_traj3, ate: 102.85302302804288
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8648/15000], training loss: 0.0586
[8656/15000], training loss: 0.0546
[8664/15000], training loss: 0.0727
[8672/15000], training loss: 0.0508
[8680/15000], training loss: 0.0849
16
AVD_Office_001_1_traj3, ate: 112.16815321534278
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8688/15000], training loss: 0.0594
[8696/15000], training loss: 0.0503
[8704/15000], training loss: 0.0555
[8712/15000], training loss: 0.0806
[8720/15000], training loss: 0.0619
16
AVD_Office_001_1_traj3, ate: 101.59770134806867
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8728/15000], training loss: 0.0539
[8736/15000], training loss: 0.0669
[8744/15000], training loss: 0.0577
[8752/15000], training loss: 0.0675
[8760/15000], training loss: 0.0698
16
AVD_Office_001_1_traj3, ate: 116.3757479314462
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8768/15000], training loss: 0.0743
[8776/15000], training loss: 0.0457
[8784/15000], training loss: 0.0514
[8792/15000], training loss: 0.0472
[8800/15000], training loss: 0.0676
16
AVD_Office_001_1_traj3, ate: 109.65588100354273
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8808/15000], training loss: 0.0707
[8816/15000], training loss: 0.0590
[8824/15000], training loss: 0.0693
[8832/15000], training loss: 0.0561
[8840/15000], training loss: 0.0885
16
AVD_Office_001_1_traj3, ate: 112.6656159879494
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8848/15000], training loss: 0.0622
[8856/15000], training loss: 0.0518
[8864/15000], training loss: 0.0650
[8872/15000], training loss: 0.0514
[8880/15000], training loss: 0.0623
16
AVD_Office_001_1_traj3, ate: 114.00923869178818
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8888/15000], training loss: 0.0722
[8896/15000], training loss: 0.0818
[8904/15000], training loss: 0.1087
[8912/15000], training loss: 0.0812
[8920/15000], training loss: 0.0665
16
AVD_Office_001_1_traj3, ate: 99.95064010554597
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8928/15000], training loss: 0.0615
[8936/15000], training loss: 0.0475
[8944/15000], training loss: 0.0642
[8952/15000], training loss: 0.0697
[8960/15000], training loss: 0.0536
16
AVD_Office_001_1_traj3, ate: 114.27131670871879
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[8968/15000], training loss: 0.0628
[8976/15000], training loss: 0.0596
[8984/15000], training loss: 0.0559
[8992/15000], training loss: 0.0627
[9000/15000], training loss: 0.0646
16
AVD_Office_001_1_traj3, ate: 112.99096377858015
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9008/15000], training loss: 0.0629
[9016/15000], training loss: 0.0673
[9024/15000], training loss: 0.0667
[9032/15000], training loss: 0.0624
[9040/15000], training loss: 0.0630
16
AVD_Office_001_1_traj3, ate: 113.14259780768936
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9048/15000], training loss: 0.0873
[9056/15000], training loss: 0.0711
[9064/15000], training loss: 0.0574
[9072/15000], training loss: 0.0614
[9080/15000], training loss: 0.0591
16
AVD_Office_001_1_traj3, ate: 108.93002480674885
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9088/15000], training loss: 0.0482
[9096/15000], training loss: 0.0545
[9104/15000], training loss: 0.0575
[9112/15000], training loss: 0.0813
[9120/15000], training loss: 0.0700
16
AVD_Office_001_1_traj3, ate: 106.21507799320246
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9128/15000], training loss: 0.0683
[9136/15000], training loss: 0.0660
[9144/15000], training loss: 0.0533
[9152/15000], training loss: 0.0845
[9160/15000], training loss: 0.0578
16
AVD_Office_001_1_traj3, ate: 109.19169590925954
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9168/15000], training loss: 0.0519
[9176/15000], training loss: 0.0657
[9184/15000], training loss: 0.0636
[9192/15000], training loss: 0.0648
[9200/15000], training loss: 0.0469
16
AVD_Office_001_1_traj3, ate: 115.33247828913906
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9208/15000], training loss: 0.0651
[9216/15000], training loss: 0.0655
[9224/15000], training loss: 0.0620
[9232/15000], training loss: 0.0651
[9240/15000], training loss: 0.0784
16
AVD_Office_001_1_traj3, ate: 122.61049696987443
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9248/15000], training loss: 0.0950
[9256/15000], training loss: 0.0772
[9264/15000], training loss: 0.0623
[9272/15000], training loss: 0.0486
[9280/15000], training loss: 0.0604
16
AVD_Office_001_1_traj3, ate: 109.30958953158891
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9288/15000], training loss: 0.0581
[9296/15000], training loss: 0.0571
[9304/15000], training loss: 0.0480
[9312/15000], training loss: 0.0534
[9320/15000], training loss: 0.0598
16
AVD_Office_001_1_traj3, ate: 110.40412784727502
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9328/15000], training loss: 0.0753
[9336/15000], training loss: 0.0711
[9344/15000], training loss: 0.0534
[9352/15000], training loss: 0.0491
[9360/15000], training loss: 0.0606
16
AVD_Office_001_1_traj3, ate: 109.0670737028732
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9368/15000], training loss: 0.0528
[9376/15000], training loss: 0.0559
[9384/15000], training loss: 0.0710
[9392/15000], training loss: 0.0510
[9400/15000], training loss: 0.0654
16
AVD_Office_001_1_traj3, ate: 114.33303737491127
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9408/15000], training loss: 0.0697
[9416/15000], training loss: 0.0617
[9424/15000], training loss: 0.0574
[9432/15000], training loss: 0.0872
[9440/15000], training loss: 0.0505
16
AVD_Office_001_1_traj3, ate: 109.6682015967149
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9448/15000], training loss: 0.0497
[9456/15000], training loss: 0.0543
[9464/15000], training loss: 0.0520
[9472/15000], training loss: 0.0734
[9480/15000], training loss: 0.0652
16
AVD_Office_001_1_traj3, ate: 101.85736233126917
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9488/15000], training loss: 0.0445
[9496/15000], training loss: 0.0483
[9504/15000], training loss: 0.0580
[9512/15000], training loss: 0.0518
[9520/15000], training loss: 0.0783
16
AVD_Office_001_1_traj3, ate: 116.13749574734702
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9528/15000], training loss: 0.0594
[9536/15000], training loss: 0.0625
[9544/15000], training loss: 0.0603
[9552/15000], training loss: 0.0639
[9560/15000], training loss: 0.0800
16
AVD_Office_001_1_traj3, ate: 107.39221308427578
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9568/15000], training loss: 0.0793
[9576/15000], training loss: 0.0837
[9584/15000], training loss: 0.0612
[9592/15000], training loss: 0.0638
[9600/15000], training loss: 0.0657
16
AVD_Office_001_1_traj3, ate: 104.04439981382497
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9608/15000], training loss: 0.0576
[9616/15000], training loss: 0.0724
[9624/15000], training loss: 0.0642
[9632/15000], training loss: 0.0615
[9640/15000], training loss: 0.0601
16
AVD_Office_001_1_traj3, ate: 94.96678791376843
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9648/15000], training loss: 0.0708
[9656/15000], training loss: 0.0508
[9664/15000], training loss: 0.0732
[9672/15000], training loss: 0.0700
[9680/15000], training loss: 0.0512
16
AVD_Office_001_1_traj3, ate: 109.56129035388581
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9688/15000], training loss: 0.0602
[9696/15000], training loss: 0.0572
[9704/15000], training loss: 0.1100
[9712/15000], training loss: 0.0560
[9720/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 118.51941849865476
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9728/15000], training loss: 0.0504
[9736/15000], training loss: 0.0494
[9744/15000], training loss: 0.0730
[9752/15000], training loss: 0.0492
[9760/15000], training loss: 0.0679
16
AVD_Office_001_1_traj3, ate: 110.95963757168225
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9768/15000], training loss: 0.0654
[9776/15000], training loss: 0.0885
[9784/15000], training loss: 0.0610
[9792/15000], training loss: 0.0505
[9800/15000], training loss: 0.0685
16
AVD_Office_001_1_traj3, ate: 113.89201888874149
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9808/15000], training loss: 0.0564
[9816/15000], training loss: 0.0460
[9824/15000], training loss: 0.0485
[9832/15000], training loss: 0.0592
[9840/15000], training loss: 0.0450
16
AVD_Office_001_1_traj3, ate: 110.47486717138064
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9848/15000], training loss: 0.0722
[9856/15000], training loss: 0.0952
[9864/15000], training loss: 0.0561
[9872/15000], training loss: 0.0678
[9880/15000], training loss: 0.0563
16
AVD_Office_001_1_traj3, ate: 110.1542647409534
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9888/15000], training loss: 0.0438
[9896/15000], training loss: 0.0688
[9904/15000], training loss: 0.0654
[9912/15000], training loss: 0.0533
[9920/15000], training loss: 0.0741
16
AVD_Office_001_1_traj3, ate: 106.720042969645
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9928/15000], training loss: 0.0519
[9936/15000], training loss: 0.0539
[9944/15000], training loss: 0.0438
[9952/15000], training loss: 0.0518
[9960/15000], training loss: 0.0598
16
AVD_Office_001_1_traj3, ate: 110.1882883584742
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[9968/15000], training loss: 0.0764
[9976/15000], training loss: 0.0781
[9984/15000], training loss: 0.0990
[9992/15000], training loss: 0.0627
[10000/15000], training loss: 0.0670
16
AVD_Office_001_1_traj3, ate: 105.46867088019441
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10008/15000], training loss: 0.0554
[10016/15000], training loss: 0.0566
[10024/15000], training loss: 0.0606
[10032/15000], training loss: 0.0581
[10040/15000], training loss: 0.0659
16
AVD_Office_001_1_traj3, ate: 123.4126946083272
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10048/15000], training loss: 0.0703
[10056/15000], training loss: 0.0685
[10064/15000], training loss: 0.0613
[10072/15000], training loss: 0.0443
[10080/15000], training loss: 0.1239
16
AVD_Office_001_1_traj3, ate: 116.97722103461604
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10088/15000], training loss: 0.0664
[10096/15000], training loss: 0.0912
[10104/15000], training loss: 0.0513
[10112/15000], training loss: 0.0681
[10120/15000], training loss: 0.0504
16
AVD_Office_001_1_traj3, ate: 102.92288950018667
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10128/15000], training loss: 0.0648
[10136/15000], training loss: 0.0423
[10144/15000], training loss: 0.0591
[10152/15000], training loss: 0.0563
[10160/15000], training loss: 0.0530
16
AVD_Office_001_1_traj3, ate: 109.54367886486132
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10168/15000], training loss: 0.0922
[10176/15000], training loss: 0.0808
[10184/15000], training loss: 0.0614
[10192/15000], training loss: 0.0573
[10200/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 107.88997337436787
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10208/15000], training loss: 0.0663
[10216/15000], training loss: 0.0452
[10224/15000], training loss: 0.0790
[10232/15000], training loss: 0.0802
[10240/15000], training loss: 0.0645
16
AVD_Office_001_1_traj3, ate: 113.20579645361963
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10248/15000], training loss: 0.0657
[10256/15000], training loss: 0.0616
[10264/15000], training loss: 0.0558
[10272/15000], training loss: 0.0784
[10280/15000], training loss: 0.0615
16
AVD_Office_001_1_traj3, ate: 110.39505811641956
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10288/15000], training loss: 0.0672
[10296/15000], training loss: 0.0661
[10304/15000], training loss: 0.0663
[10312/15000], training loss: 0.0450
[10320/15000], training loss: 0.0581
16
AVD_Office_001_1_traj3, ate: 107.50663554064457
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10328/15000], training loss: 0.0867
[10336/15000], training loss: 0.1011
[10344/15000], training loss: 0.0612
[10352/15000], training loss: 0.0618
[10360/15000], training loss: 0.0754
16
AVD_Office_001_1_traj3, ate: 101.2980731608816
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10368/15000], training loss: 0.0697
[10376/15000], training loss: 0.0496
[10384/15000], training loss: 0.0556
[10392/15000], training loss: 0.0664
[10400/15000], training loss: 0.0495
16
AVD_Office_001_1_traj3, ate: 111.66289730505287
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10408/15000], training loss: 0.0749
[10416/15000], training loss: 0.0609
[10424/15000], training loss: 0.0692
[10432/15000], training loss: 0.0535
[10440/15000], training loss: 0.0806
16
AVD_Office_001_1_traj3, ate: 104.52355604885439
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10448/15000], training loss: 0.0649
[10456/15000], training loss: 0.0592
[10464/15000], training loss: 0.0681
[10472/15000], training loss: 0.0538
[10480/15000], training loss: 0.0668
16
AVD_Office_001_1_traj3, ate: 105.84207001940965
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10488/15000], training loss: 0.0507
[10496/15000], training loss: 0.0473
[10504/15000], training loss: 0.0648
[10512/15000], training loss: 0.0572
[10520/15000], training loss: 0.0776
16
AVD_Office_001_1_traj3, ate: 110.48394265379993
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10528/15000], training loss: 0.0548
[10536/15000], training loss: 0.0586
[10544/15000], training loss: 0.0945
[10552/15000], training loss: 0.0847
[10560/15000], training loss: 0.0735
16
AVD_Office_001_1_traj3, ate: 105.78816041367668
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10568/15000], training loss: 0.0549
[10576/15000], training loss: 0.0693
[10584/15000], training loss: 0.0699
[10592/15000], training loss: 0.0760
[10600/15000], training loss: 0.0561
16
AVD_Office_001_1_traj3, ate: 104.19616375766154
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10608/15000], training loss: 0.0730
[10616/15000], training loss: 0.0591
[10624/15000], training loss: 0.0475
[10632/15000], training loss: 0.0582
[10640/15000], training loss: 0.0584
16
AVD_Office_001_1_traj3, ate: 111.03869281046046
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10648/15000], training loss: 0.0874
[10656/15000], training loss: 0.0703
[10664/15000], training loss: 0.0583
[10672/15000], training loss: 0.0566
[10680/15000], training loss: 0.0512
16
AVD_Office_001_1_traj3, ate: 108.66030779467819
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10688/15000], training loss: 0.0636
[10696/15000], training loss: 0.0573
[10704/15000], training loss: 0.0525
[10712/15000], training loss: 0.0459
[10720/15000], training loss: 0.0621
16
AVD_Office_001_1_traj3, ate: 124.9224958052509
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10728/15000], training loss: 0.0542
[10736/15000], training loss: 0.0608
[10744/15000], training loss: 0.0993
[10752/15000], training loss: 0.0843
[10760/15000], training loss: 0.0616
16
AVD_Office_001_1_traj3, ate: 111.83136403353517
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10768/15000], training loss: 0.0594
[10776/15000], training loss: 0.0563
[10784/15000], training loss: 0.0642
[10792/15000], training loss: 0.0654
[10800/15000], training loss: 0.0496
16
AVD_Office_001_1_traj3, ate: 119.87094907265589
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10808/15000], training loss: 0.0685
[10816/15000], training loss: 0.0771
[10824/15000], training loss: 0.0488
[10832/15000], training loss: 0.0678
[10840/15000], training loss: 0.0701
16
AVD_Office_001_1_traj3, ate: 106.51755805694498
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10848/15000], training loss: 0.0705
[10856/15000], training loss: 0.0558
[10864/15000], training loss: 0.0747
[10872/15000], training loss: 0.0437
[10880/15000], training loss: 0.0565
16
AVD_Office_001_1_traj3, ate: 100.11144007527912
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10888/15000], training loss: 0.0912
[10896/15000], training loss: 0.0704
[10904/15000], training loss: 0.0693
[10912/15000], training loss: 0.0611
[10920/15000], training loss: 0.0674
16
AVD_Office_001_1_traj3, ate: 102.19950611268884
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10928/15000], training loss: 0.0590
[10936/15000], training loss: 0.0650
[10944/15000], training loss: 0.0632
[10952/15000], training loss: 0.0455
[10960/15000], training loss: 0.0512
16
AVD_Office_001_1_traj3, ate: 113.31651941597505
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[10968/15000], training loss: 0.0526
[10976/15000], training loss: 0.0968
[10984/15000], training loss: 0.0548
[10992/15000], training loss: 0.0749
[11000/15000], training loss: 0.0648
16
AVD_Office_001_1_traj3, ate: 103.02766041276801
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11008/15000], training loss: 0.0946
[11016/15000], training loss: 0.0628
[11024/15000], training loss: 0.0704
[11032/15000], training loss: 0.0594
[11040/15000], training loss: 0.0865
16
AVD_Office_001_1_traj3, ate: 103.63671887112733
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11048/15000], training loss: 0.0571
[11056/15000], training loss: 0.0511
[11064/15000], training loss: 0.0669
[11072/15000], training loss: 0.0768
[11080/15000], training loss: 0.0490
16
AVD_Office_001_1_traj3, ate: 101.30322940605873
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11088/15000], training loss: 0.0487
[11096/15000], training loss: 0.0741
[11104/15000], training loss: 0.0562
[11112/15000], training loss: 0.1135
[11120/15000], training loss: 0.0652
16
AVD_Office_001_1_traj3, ate: 106.01028836566024
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11128/15000], training loss: 0.0606
[11136/15000], training loss: 0.0772
[11144/15000], training loss: 0.0823
[11152/15000], training loss: 0.0485
[11160/15000], training loss: 0.0740
16
AVD_Office_001_1_traj3, ate: 106.16998655705545
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11168/15000], training loss: 0.0679
[11176/15000], training loss: 0.0430
[11184/15000], training loss: 0.0523
[11192/15000], training loss: 0.0684
[11200/15000], training loss: 0.0860
16
AVD_Office_001_1_traj3, ate: 106.43243284344415
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11208/15000], training loss: 0.0782
[11216/15000], training loss: 0.0578
[11224/15000], training loss: 0.0579
[11232/15000], training loss: 0.0609
[11240/15000], training loss: 0.0536
16
AVD_Office_001_1_traj3, ate: 109.6025836315556
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11248/15000], training loss: 0.0699
[11256/15000], training loss: 0.0508
[11264/15000], training loss: 0.0615
[11272/15000], training loss: 0.0749
[11280/15000], training loss: 0.0585
16
AVD_Office_001_1_traj3, ate: 102.53271501791237
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11288/15000], training loss: 0.0456
[11296/15000], training loss: 0.0568
[11304/15000], training loss: 0.0677
[11312/15000], training loss: 0.0543
[11320/15000], training loss: 0.0753
16
AVD_Office_001_1_traj3, ate: 108.23134558241989
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11328/15000], training loss: 0.0630
[11336/15000], training loss: 0.0601
[11344/15000], training loss: 0.0558
[11352/15000], training loss: 0.0628
[11360/15000], training loss: 0.0659
16
AVD_Office_001_1_traj3, ate: 106.10027103747974
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11368/15000], training loss: 0.0761
[11376/15000], training loss: 0.0613
[11384/15000], training loss: 0.0560
[11392/15000], training loss: 0.0529
[11400/15000], training loss: 0.0520
16
AVD_Office_001_1_traj3, ate: 108.0311854952128
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11408/15000], training loss: 0.0446
[11416/15000], training loss: 0.0582
[11424/15000], training loss: 0.0648
[11432/15000], training loss: 0.0539
[11440/15000], training loss: 0.0563
16
AVD_Office_001_1_traj3, ate: 115.25659643229883
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11448/15000], training loss: 0.0513
[11456/15000], training loss: 0.0792
[11464/15000], training loss: 0.0558
[11472/15000], training loss: 0.0667
[11480/15000], training loss: 0.0552
16
AVD_Office_001_1_traj3, ate: 113.41696421991617
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11488/15000], training loss: 0.0580
[11496/15000], training loss: 0.0891
[11504/15000], training loss: 0.0793
[11512/15000], training loss: 0.0777
[11520/15000], training loss: 0.0651
16
AVD_Office_001_1_traj3, ate: 97.50644452195918
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11528/15000], training loss: 0.0656
[11536/15000], training loss: 0.0829
[11544/15000], training loss: 0.0590
[11552/15000], training loss: 0.0517
[11560/15000], training loss: 0.0533
16
AVD_Office_001_1_traj3, ate: 103.77160262710811
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11568/15000], training loss: 0.0568
[11576/15000], training loss: 0.0629
[11584/15000], training loss: 0.0505
[11592/15000], training loss: 0.0641
[11600/15000], training loss: 0.0527
16
AVD_Office_001_1_traj3, ate: 117.89669893906887
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11608/15000], training loss: 0.0722
[11616/15000], training loss: 0.0646
[11624/15000], training loss: 0.0486
[11632/15000], training loss: 0.0522
[11640/15000], training loss: 0.0542
16
AVD_Office_001_1_traj3, ate: 115.20168108886335
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11648/15000], training loss: 0.0711
[11656/15000], training loss: 0.0666
[11664/15000], training loss: 0.0616
[11672/15000], training loss: 0.0669
[11680/15000], training loss: 0.0439
16
AVD_Office_001_1_traj3, ate: 110.93936378264968
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11688/15000], training loss: 0.0571
[11696/15000], training loss: 0.0656
[11704/15000], training loss: 0.0422
[11712/15000], training loss: 0.0587
[11720/15000], training loss: 0.0527
16
AVD_Office_001_1_traj3, ate: 105.6624381374924
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11728/15000], training loss: 0.0489
[11736/15000], training loss: 0.0510
[11744/15000], training loss: 0.0663
[11752/15000], training loss: 0.0483
[11760/15000], training loss: 0.0822
16
AVD_Office_001_1_traj3, ate: 107.45713744306983
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11768/15000], training loss: 0.0592
[11776/15000], training loss: 0.0452
[11784/15000], training loss: 0.0620
[11792/15000], training loss: 0.0729
[11800/15000], training loss: 0.0600
16
AVD_Office_001_1_traj3, ate: 109.05873123723177
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11808/15000], training loss: 0.0473
[11816/15000], training loss: 0.0576
[11824/15000], training loss: 0.0710
[11832/15000], training loss: 0.0682
[11840/15000], training loss: 0.0712
16
AVD_Office_001_1_traj3, ate: 101.95979851229613
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11848/15000], training loss: 0.0574
[11856/15000], training loss: 0.0552
[11864/15000], training loss: 0.0896
[11872/15000], training loss: 0.0558
[11880/15000], training loss: 0.0917
16
AVD_Office_001_1_traj3, ate: 99.56318881054798
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11888/15000], training loss: 0.0511
[11896/15000], training loss: 0.0735
[11904/15000], training loss: 0.0486
[11912/15000], training loss: 0.0928
[11920/15000], training loss: 0.0618
16
AVD_Office_001_1_traj3, ate: 100.79321478311181
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11928/15000], training loss: 0.0766
[11936/15000], training loss: 0.0610
[11944/15000], training loss: 0.0603
[11952/15000], training loss: 0.0583
[11960/15000], training loss: 0.0820
16
AVD_Office_001_1_traj3, ate: 103.96907643810526
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[11968/15000], training loss: 0.0837
[11976/15000], training loss: 0.0722
[11984/15000], training loss: 0.0785
[11992/15000], training loss: 0.0510
[12000/15000], training loss: 0.0687
16
AVD_Office_001_1_traj3, ate: 102.98813093928301
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12008/15000], training loss: 0.0722
[12016/15000], training loss: 0.0640
[12024/15000], training loss: 0.0739
[12032/15000], training loss: 0.0492
[12040/15000], training loss: 0.0646
16
AVD_Office_001_1_traj3, ate: 103.87265653224478
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12048/15000], training loss: 0.0768
[12056/15000], training loss: 0.0542
[12064/15000], training loss: 0.0837
[12072/15000], training loss: 0.0611
[12080/15000], training loss: 0.0541
16
AVD_Office_001_1_traj3, ate: 106.42005050619137
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12088/15000], training loss: 0.0777
[12096/15000], training loss: 0.0799
[12104/15000], training loss: 0.0675
[12112/15000], training loss: 0.0769
[12120/15000], training loss: 0.0511
16
AVD_Office_001_1_traj3, ate: 103.05572070918947
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12128/15000], training loss: 0.0694
[12136/15000], training loss: 0.0467
[12144/15000], training loss: 0.0576
[12152/15000], training loss: 0.0753
[12160/15000], training loss: 0.0798
16
AVD_Office_001_1_traj3, ate: 110.76880635025124
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12168/15000], training loss: 0.0659
[12176/15000], training loss: 0.0536
[12184/15000], training loss: 0.0820
[12192/15000], training loss: 0.0641
[12200/15000], training loss: 0.0649
16
AVD_Office_001_1_traj3, ate: 105.97035092745398
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12208/15000], training loss: 0.0705
[12216/15000], training loss: 0.0553
[12224/15000], training loss: 0.0614
[12232/15000], training loss: 0.0605
[12240/15000], training loss: 0.0616
16
AVD_Office_001_1_traj3, ate: 100.03097964733962
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12248/15000], training loss: 0.0714
[12256/15000], training loss: 0.0629
[12264/15000], training loss: 0.0567
[12272/15000], training loss: 0.0528
[12280/15000], training loss: 0.0641
16
AVD_Office_001_1_traj3, ate: 106.34383478338123
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12288/15000], training loss: 0.0506
[12296/15000], training loss: 0.0714
[12304/15000], training loss: 0.0529
[12312/15000], training loss: 0.0587
[12320/15000], training loss: 0.0558
16
AVD_Office_001_1_traj3, ate: 105.60705781540476
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12328/15000], training loss: 0.0722
[12336/15000], training loss: 0.0527
[12344/15000], training loss: 0.0714
[12352/15000], training loss: 0.0687
[12360/15000], training loss: 0.0442
16
AVD_Office_001_1_traj3, ate: 106.63995131426333
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12368/15000], training loss: 0.0413
[12376/15000], training loss: 0.0722
[12384/15000], training loss: 0.0648
[12392/15000], training loss: 0.0757
[12400/15000], training loss: 0.0616
16
AVD_Office_001_1_traj3, ate: 105.64301393699859
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12408/15000], training loss: 0.0717
[12416/15000], training loss: 0.0629
[12424/15000], training loss: 0.0757
[12432/15000], training loss: 0.0695
[12440/15000], training loss: 0.0541
16
AVD_Office_001_1_traj3, ate: 111.27024134952003
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12448/15000], training loss: 0.0573
[12456/15000], training loss: 0.0491
[12464/15000], training loss: 0.0694
[12472/15000], training loss: 0.0750
[12480/15000], training loss: 0.0670
16
AVD_Office_001_1_traj3, ate: 106.23675501265318
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12488/15000], training loss: 0.0607
[12496/15000], training loss: 0.0625
[12504/15000], training loss: 0.0447
[12512/15000], training loss: 0.0504
[12520/15000], training loss: 0.0555
16
AVD_Office_001_1_traj3, ate: 109.4870995190171
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12528/15000], training loss: 0.0764
[12536/15000], training loss: 0.0794
[12544/15000], training loss: 0.0820
[12552/15000], training loss: 0.0592
[12560/15000], training loss: 0.0616
16
AVD_Office_001_1_traj3, ate: 103.80421815748451
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12568/15000], training loss: 0.0613
[12576/15000], training loss: 0.0699
[12584/15000], training loss: 0.0550
[12592/15000], training loss: 0.0576
[12600/15000], training loss: 0.0463
16
AVD_Office_001_1_traj3, ate: 99.35282427623787
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12608/15000], training loss: 0.0460
[12616/15000], training loss: 0.0582
[12624/15000], training loss: 0.0511
[12632/15000], training loss: 0.0458
[12640/15000], training loss: 0.0851
16
AVD_Office_001_1_traj3, ate: 101.21751170460657
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12648/15000], training loss: 0.0702
[12656/15000], training loss: 0.0517
[12664/15000], training loss: 0.0665
[12672/15000], training loss: 0.0490
[12680/15000], training loss: 0.0658
16
AVD_Office_001_1_traj3, ate: 105.31570307352278
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12688/15000], training loss: 0.0595
[12696/15000], training loss: 0.0741
[12704/15000], training loss: 0.0501
[12712/15000], training loss: 0.0523
[12720/15000], training loss: 0.0596
16
AVD_Office_001_1_traj3, ate: 108.79068786114598
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12728/15000], training loss: 0.0771
[12736/15000], training loss: 0.0553
[12744/15000], training loss: 0.0613
[12752/15000], training loss: 0.0581
[12760/15000], training loss: 0.0649
16
AVD_Office_001_1_traj3, ate: 99.49637700586821
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12768/15000], training loss: 0.0410
[12776/15000], training loss: 0.0455
[12784/15000], training loss: 0.0595
[12792/15000], training loss: 0.0855
[12800/15000], training loss: 0.0602
16
AVD_Office_001_1_traj3, ate: 101.17455845471672
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12808/15000], training loss: 0.0499
[12816/15000], training loss: 0.0552
[12824/15000], training loss: 0.0591
[12832/15000], training loss: 0.0850
[12840/15000], training loss: 0.0793
16
AVD_Office_001_1_traj3, ate: 101.33012678471214
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12848/15000], training loss: 0.0775
[12856/15000], training loss: 0.0725
[12864/15000], training loss: 0.0494
[12872/15000], training loss: 0.0598
[12880/15000], training loss: 0.0617
16
AVD_Office_001_1_traj3, ate: 99.19261422817468
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12888/15000], training loss: 0.0771
[12896/15000], training loss: 0.0707
[12904/15000], training loss: 0.0778
[12912/15000], training loss: 0.0792
[12920/15000], training loss: 0.1014
16
AVD_Office_001_1_traj3, ate: 100.70600256201179
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12928/15000], training loss: 0.0452
[12936/15000], training loss: 0.0876
[12944/15000], training loss: 0.0581
[12952/15000], training loss: 0.0560
[12960/15000], training loss: 0.1129
16
AVD_Office_001_1_traj3, ate: 104.85684091581676
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[12968/15000], training loss: 0.0633
[12976/15000], training loss: 0.0571
[12984/15000], training loss: 0.0606
[12992/15000], training loss: 0.0568
[13000/15000], training loss: 0.0610
16
AVD_Office_001_1_traj3, ate: 100.23985782931577
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13008/15000], training loss: 0.0634
[13016/15000], training loss: 0.0536
[13024/15000], training loss: 0.0399
[13032/15000], training loss: 0.0611
[13040/15000], training loss: 0.0577
16
AVD_Office_001_1_traj3, ate: 94.54364943369237
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13048/15000], training loss: 0.0509
[13056/15000], training loss: 0.0661
[13064/15000], training loss: 0.0562
[13072/15000], training loss: 0.0484
[13080/15000], training loss: 0.0754
16
AVD_Office_001_1_traj3, ate: 103.9140691158411
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13088/15000], training loss: 0.0636
[13096/15000], training loss: 0.0804
[13104/15000], training loss: 0.0599
[13112/15000], training loss: 0.0605
[13120/15000], training loss: 0.0542
16
AVD_Office_001_1_traj3, ate: 94.02093620914549
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13128/15000], training loss: 0.0587
[13136/15000], training loss: 0.0694
[13144/15000], training loss: 0.0540
[13152/15000], training loss: 0.0472
[13160/15000], training loss: 0.0566
16
AVD_Office_001_1_traj3, ate: 101.20741243413126
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13168/15000], training loss: 0.0770
[13176/15000], training loss: 0.0737
[13184/15000], training loss: 0.0432
[13192/15000], training loss: 0.0498
[13200/15000], training loss: 0.0599
16
AVD_Office_001_1_traj3, ate: 103.47917052460042
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13208/15000], training loss: 0.0605
[13216/15000], training loss: 0.0645
[13224/15000], training loss: 0.0609
[13232/15000], training loss: 0.0589
[13240/15000], training loss: 0.0568
16
AVD_Office_001_1_traj3, ate: 100.87214085362584
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13248/15000], training loss: 0.0491
[13256/15000], training loss: 0.0648
[13264/15000], training loss: 0.0890
[13272/15000], training loss: 0.0690
[13280/15000], training loss: 0.0498
16
AVD_Office_001_1_traj3, ate: 96.43127116563919
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13288/15000], training loss: 0.0551
[13296/15000], training loss: 0.0561
[13304/15000], training loss: 0.0661
[13312/15000], training loss: 0.0441
[13320/15000], training loss: 0.0497
16
AVD_Office_001_1_traj3, ate: 101.88525752851986
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13328/15000], training loss: 0.0845
[13336/15000], training loss: 0.0545
[13344/15000], training loss: 0.0813
[13352/15000], training loss: 0.0665
[13360/15000], training loss: 0.0393
16
AVD_Office_001_1_traj3, ate: 111.87217407587615
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13368/15000], training loss: 0.0471
[13376/15000], training loss: 0.0693
[13384/15000], training loss: 0.0626
[13392/15000], training loss: 0.0485
[13400/15000], training loss: 0.0609
16
AVD_Office_001_1_traj3, ate: 93.72556715804254
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13408/15000], training loss: 0.0618
[13416/15000], training loss: 0.0527
[13424/15000], training loss: 0.0825
[13432/15000], training loss: 0.0477
[13440/15000], training loss: 0.0587
16
AVD_Office_001_1_traj3, ate: 96.30342271667773
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13448/15000], training loss: 0.0668
[13456/15000], training loss: 0.0632
[13464/15000], training loss: 0.0717
[13472/15000], training loss: 0.0502
[13480/15000], training loss: 0.0419
16
AVD_Office_001_1_traj3, ate: 98.31349631920936
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13488/15000], training loss: 0.0597
[13496/15000], training loss: 0.0487
[13504/15000], training loss: 0.0609
[13512/15000], training loss: 0.0571
[13520/15000], training loss: 0.0510
16
AVD_Office_001_1_traj3, ate: 99.87583652246546
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13528/15000], training loss: 0.0441
[13536/15000], training loss: 0.0481
[13544/15000], training loss: 0.0668
[13552/15000], training loss: 0.0466
[13560/15000], training loss: 0.0509
16
AVD_Office_001_1_traj3, ate: 97.88543091616431
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13568/15000], training loss: 0.0611
[13576/15000], training loss: 0.0609
[13584/15000], training loss: 0.0691
[13592/15000], training loss: 0.0596
[13600/15000], training loss: 0.0592
16
AVD_Office_001_1_traj3, ate: 103.35723288154642
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13608/15000], training loss: 0.0572
[13616/15000], training loss: 0.0672
[13624/15000], training loss: 0.0442
[13632/15000], training loss: 0.0651
[13640/15000], training loss: 0.0789
16
AVD_Office_001_1_traj3, ate: 94.6058891264092
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13648/15000], training loss: 0.0656
[13656/15000], training loss: 0.0566
[13664/15000], training loss: 0.0604
[13672/15000], training loss: 0.0965
[13680/15000], training loss: 0.0661
16
AVD_Office_001_1_traj3, ate: 101.8647226564433
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13688/15000], training loss: 0.0702
[13696/15000], training loss: 0.0650
[13704/15000], training loss: 0.0507
[13712/15000], training loss: 0.0728
[13720/15000], training loss: 0.0501
16
AVD_Office_001_1_traj3, ate: 100.04946545696572
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13728/15000], training loss: 0.0608
[13736/15000], training loss: 0.0755
[13744/15000], training loss: 0.0507
[13752/15000], training loss: 0.0595
[13760/15000], training loss: 0.0707
16
AVD_Office_001_1_traj3, ate: 97.93983608816193
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13768/15000], training loss: 0.0706
[13776/15000], training loss: 0.0542
[13784/15000], training loss: 0.0569
[13792/15000], training loss: 0.0627
[13800/15000], training loss: 0.0889
16
AVD_Office_001_1_traj3, ate: 96.85819804906852
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13808/15000], training loss: 0.0825
[13816/15000], training loss: 0.0627
[13824/15000], training loss: 0.0672
[13832/15000], training loss: 0.0641
[13840/15000], training loss: 0.0768
16
AVD_Office_001_1_traj3, ate: 93.97684682561272
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13848/15000], training loss: 0.0730
[13856/15000], training loss: 0.0420
[13864/15000], training loss: 0.0555
[13872/15000], training loss: 0.0629
[13880/15000], training loss: 0.0486
16
AVD_Office_001_1_traj3, ate: 99.31349710193686
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13888/15000], training loss: 0.0530
[13896/15000], training loss: 0.0446
[13904/15000], training loss: 0.0558
[13912/15000], training loss: 0.0532
[13920/15000], training loss: 0.0589
16
AVD_Office_001_1_traj3, ate: 103.70372421708018
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13928/15000], training loss: 0.0586
[13936/15000], training loss: 0.0784
[13944/15000], training loss: 0.0683
[13952/15000], training loss: 0.1207
[13960/15000], training loss: 0.0448
16
AVD_Office_001_1_traj3, ate: 99.38811629146204
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[13968/15000], training loss: 0.0736
[13976/15000], training loss: 0.0637
[13984/15000], training loss: 0.0630
[13992/15000], training loss: 0.0629
[14000/15000], training loss: 0.0570
16
AVD_Office_001_1_traj3, ate: 95.61646185386235
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14008/15000], training loss: 0.1452
[14016/15000], training loss: 0.0495
[14024/15000], training loss: 0.0692
[14032/15000], training loss: 0.0971
[14040/15000], training loss: 0.0490
16
AVD_Office_001_1_traj3, ate: 102.74264488843231
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14048/15000], training loss: 0.0572
[14056/15000], training loss: 0.0634
[14064/15000], training loss: 0.0483
[14072/15000], training loss: 0.0595
[14080/15000], training loss: 0.0653
16
AVD_Office_001_1_traj3, ate: 97.34555792312102
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14088/15000], training loss: 0.0600
[14096/15000], training loss: 0.0637
[14104/15000], training loss: 0.0664
[14112/15000], training loss: 0.0564
[14120/15000], training loss: 0.0682
16
AVD_Office_001_1_traj3, ate: 95.1219184739725
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14128/15000], training loss: 0.0660
[14136/15000], training loss: 0.0682
[14144/15000], training loss: 0.0712
[14152/15000], training loss: 0.0516
[14160/15000], training loss: 0.0651
16
AVD_Office_001_1_traj3, ate: 94.78819410080044
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14168/15000], training loss: 0.0556
[14176/15000], training loss: 0.0482
[14184/15000], training loss: 0.0650
[14192/15000], training loss: 0.0494
[14200/15000], training loss: 0.0508
16
AVD_Office_001_1_traj3, ate: 101.8578684890771
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14208/15000], training loss: 0.0652
[14216/15000], training loss: 0.0642
[14224/15000], training loss: 0.0354
[14232/15000], training loss: 0.0492
[14240/15000], training loss: 0.0454
16
AVD_Office_001_1_traj3, ate: 100.00627587997062
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14248/15000], training loss: 0.0472
[14256/15000], training loss: 0.0504
[14264/15000], training loss: 0.0614
[14272/15000], training loss: 0.0814
[14280/15000], training loss: 0.0624
16
AVD_Office_001_1_traj3, ate: 93.84886167010775
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14288/15000], training loss: 0.0613
[14296/15000], training loss: 0.0858
[14304/15000], training loss: 0.0513
[14312/15000], training loss: 0.0664
[14320/15000], training loss: 0.0670
16
AVD_Office_001_1_traj3, ate: 93.23085275584673
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14328/15000], training loss: 0.0568
[14336/15000], training loss: 0.0772
[14344/15000], training loss: 0.0739
[14352/15000], training loss: 0.0601
[14360/15000], training loss: 0.0633
16
AVD_Office_001_1_traj3, ate: 94.59230637597406
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14368/15000], training loss: 0.0584
[14376/15000], training loss: 0.0505
[14384/15000], training loss: 0.0639
[14392/15000], training loss: 0.0519
[14400/15000], training loss: 0.0702
16
AVD_Office_001_1_traj3, ate: 95.88157682918312
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14408/15000], training loss: 0.0489
[14416/15000], training loss: 0.0537
[14424/15000], training loss: 0.0451
[14432/15000], training loss: 0.0955
[14440/15000], training loss: 0.0525
16
AVD_Office_001_1_traj3, ate: 98.62256594731498
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14448/15000], training loss: 0.0508
[14456/15000], training loss: 0.0528
[14464/15000], training loss: 0.0519
[14472/15000], training loss: 0.0656
[14480/15000], training loss: 0.0774
16
AVD_Office_001_1_traj3, ate: 90.33052980490444
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14488/15000], training loss: 0.0639
[14496/15000], training loss: 0.0573
[14504/15000], training loss: 0.0519
[14512/15000], training loss: 0.0432
[14520/15000], training loss: 0.0553
16
AVD_Office_001_1_traj3, ate: 103.57525866296872
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14528/15000], training loss: 0.0722
[14536/15000], training loss: 0.0497
[14544/15000], training loss: 0.0553
[14552/15000], training loss: 0.0699
[14560/15000], training loss: 0.0518
16
AVD_Office_001_1_traj3, ate: 93.45329781662223
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14568/15000], training loss: 0.0648
[14576/15000], training loss: 0.0503
[14584/15000], training loss: 0.0478
[14592/15000], training loss: 0.0627
[14600/15000], training loss: 0.0403
16
AVD_Office_001_1_traj3, ate: 98.77435557755838
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14608/15000], training loss: 0.0488
[14616/15000], training loss: 0.0467
[14624/15000], training loss: 0.0653
[14632/15000], training loss: 0.0570
[14640/15000], training loss: 0.1016
16
AVD_Office_001_1_traj3, ate: 92.25794234862026
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14648/15000], training loss: 0.0678
[14656/15000], training loss: 0.0714
[14664/15000], training loss: 0.0626
[14672/15000], training loss: 0.0637
[14680/15000], training loss: 0.0743
16
AVD_Office_001_1_traj3, ate: 97.45213841351857
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14688/15000], training loss: 0.0474
[14696/15000], training loss: 0.0536
[14704/15000], training loss: 0.0612
[14712/15000], training loss: 0.0383
[14720/15000], training loss: 0.0540
16
AVD_Office_001_1_traj3, ate: 96.64718315746082
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14728/15000], training loss: 0.0637
[14736/15000], training loss: 0.0464
[14744/15000], training loss: 0.0399
[14752/15000], training loss: 0.0551
[14760/15000], training loss: 0.0652
16
AVD_Office_001_1_traj3, ate: 100.27264776123019
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14768/15000], training loss: 0.0398
[14776/15000], training loss: 0.0489
[14784/15000], training loss: 0.0669
[14792/15000], training loss: 0.0520
[14800/15000], training loss: 0.0870
16
AVD_Office_001_1_traj3, ate: 98.44368032842614
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14808/15000], training loss: 0.0484
[14816/15000], training loss: 0.0625
[14824/15000], training loss: 0.0541
[14832/15000], training loss: 0.0460
[14840/15000], training loss: 0.0512
16
AVD_Office_001_1_traj3, ate: 102.6484466150284
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14848/15000], training loss: 0.0525
[14856/15000], training loss: 0.0525
[14864/15000], training loss: 0.0673
[14872/15000], training loss: 0.0805
[14880/15000], training loss: 0.0521
16
AVD_Office_001_1_traj3, ate: 93.92728683591055
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14888/15000], training loss: 0.0702
[14896/15000], training loss: 0.0541
[14904/15000], training loss: 0.0607
[14912/15000], training loss: 0.0637
[14920/15000], training loss: 0.0911
16
AVD_Office_001_1_traj3, ate: 94.5359558638867
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14928/15000], training loss: 0.0509
[14936/15000], training loss: 0.0416
[14944/15000], training loss: 0.0658
[14952/15000], training loss: 0.0639
[14960/15000], training loss: 0.0548
16
AVD_Office_001_1_traj3, ate: 102.90700469077049
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
[14968/15000], training loss: 0.0461
[14976/15000], training loss: 0.0449
[14984/15000], training loss: 0.0794
[14992/15000], training loss: 0.0625
[15000/15000], training loss: 0.0651
16
AVD_Office_001_1_traj3, ate: 104.85106729567245
model saved to ../results/AVD/AVD_Office_001_1_traj3/model_best.pth
./lstm_run_train_AVD.sh: line 25: /home/mmvc: Is a directory
